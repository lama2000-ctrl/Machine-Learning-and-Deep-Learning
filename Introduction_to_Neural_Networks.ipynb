{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction and Dataset Description\n",
        "Since this is an introductory article, the problem that we are going to solve is pretty simple. Suppose we have some information about obesity, smoking habits, and exercise habits of five people. We also know whether these people are diabetic or not. Our dataset looks like this."
      ],
      "metadata": {
        "id": "VVUqg5QIUPH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!gdown --id -q 1EJmU7Mli1oXLPJfXGrus0HHfVnXM6wpk\n",
        "!unzip -q Data.zip\n",
        "\n",
        "data = pd.read_csv('Data.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0cGHM4vAXAdu",
        "outputId": "78cd56ed-888d-4059-ed12-5087ee188b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d99934a2-3e00-4bb8-917d-b827d1e69b21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Person</th>\n",
              "      <th>Smoking</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>Exercise</th>\n",
              "      <th>Diabetic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Person 1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Person 2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Person 3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Person 4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Person 5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d99934a2-3e00-4bb8-917d-b827d1e69b21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d99934a2-3e00-4bb8-917d-b827d1e69b21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d99934a2-3e00-4bb8-917d-b827d1e69b21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Person  Smoking  Obesity  Exercise  Diabetic\n",
              "0  Person 1        0        1         0         1\n",
              "1  Person 2        0        0         1         0\n",
              "2  Person 3        1        0         0         0\n",
              "3  Person 4        1        1         0         1\n",
              "4  Person 5        1        1         1         1"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above table, we have five columns: Person, Smoking, Obesity, Exercise, and Diabetic. Here 1 refers to true and 0 refers to false. For instance, the first person has values of 0, 1, 0 which means that the person doesn't smoke, is obese, and doesn't exercise. The person is also diabetic.\n",
        "\n",
        "It is clearly evident from the dataset that a person's obesity is indicative of him being diabetic. Our task is to create a neural network that is able to predict whether an unknown person is diabetic or not from the given data about his exercise habits, obesity, and smoking habits. This is a type of supervised learning problem where we are given inputs and corresponding correct outputs and our task is to find the mapping between the inputs and the outputs.\n",
        "\n",
        "**Note**: This is just a fictional dataset, in real life, obese people are not necessarily always diabetic."
      ],
      "metadata": {
        "id": "3iJEu5IQZFsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Solution\n",
        "We will create a very simple neural network with one input layer, one hidden layer (that will contain two hidden units) and one output layer. Before writing any actual code, let's first let's see how our neural network will execute, in theory. For simplicity, we are not considering the bias term.<br>\n",
        "![nn.JPG](data:image/jpeg;base64,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)\n",
        "\n"
      ],
      "metadata": {
        "id": "xiq8T7AsVOBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating feature values from labels"
      ],
      "metadata": {
        "id": "eDhseI6GbSVu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFlEMtARUD78",
        "outputId": "2ca9d3dd-9cf2-4036-e3fa-fc688984b786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:\n",
            " [[0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 1 0]\n",
            " [1 1 1]]\n",
            "y:\n",
            " [[1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]]\n"
          ]
        }
      ],
      "source": [
        "data_np = data.to_numpy()\n",
        "X = data_np[:,[1,2,3]]\n",
        "y = data_np[:,4]\n",
        "y = np.atleast_2d(y).T\n",
        "\n",
        "print(f'X:\\n {X}')\n",
        "print(f'y:\\n {y}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight Initialization\n",
        "At first, we will consider random weights. We will store the weights values for input layer and hidden layer in matrix `w1`. Weight values for hidden layer and output layer will be stored in matrix `w2`.<br>\n",
        "Since, there are 3 input units and 2 hidden units, the dimension of matrix `w1` will be 3 × 2. For the same reason, dimension of matrix `w2` will be 2 × 1."
      ],
      "metadata": {
        "id": "9IvSyAhobcjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_neurons_in_input_layer = len(X[0])\n",
        "number_of_neurons_in_hidden_layer = 2\n",
        "number_of_neurons_in_output_layer = 1\n",
        "\n",
        "w1 = np.random.random((number_of_neurons_in_input_layer, number_of_neurons_in_hidden_layer))\n",
        "w2 = np.random.random((number_of_neurons_in_hidden_layer, number_of_neurons_in_output_layer))\n",
        "\n",
        "print(f'w1:\\n {w1}')\n",
        "print(f'w2:\\n {w2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nhmu5s_aHUV",
        "outputId": "72aa9d89-1502-4643-fcfc-3b0670e4fb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1:\n",
            " [[0.10349165 0.19761654]\n",
            " [0.07107635 0.07374558]\n",
            " [0.48644549 0.16289995]]\n",
            "w2:\n",
            " [[0.95875465]\n",
            " [0.01068502]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward Propagation\n",
        "At first, we will calculate the weighted sum by multiplying `X` with `w1`. Let this result be $z_{h}$.<br>\n",
        "$$z_h = \\sum_{i=1}^{X} x_iw_{1_i}$$"
      ],
      "metadata": {
        "id": "4PkeffiRdqZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_h=np.matmul(X,w1)\n",
        "print(f'z_h:\\n {z_h}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIfNY230bnFN",
        "outputId": "40a4f3e5-9a1e-478e-d4a6-a0cf46927833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z_h:\n",
            " [[0.0710763542188434 0.07374557535167514]\n",
            " [0.48644548572535706 0.16289994568014987]\n",
            " [0.10349164667036814 0.1976165379165512]\n",
            " [0.17456800088921154 0.27136211326822635]\n",
            " [0.6610134866145686 0.4342620589483762]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$z_{h}$ is the value of hidden layer. To keep this value between 0 and 1, we will pass it through a `sigmoid` function and calculate `a_h`.<br>\n",
        "$$sigmoid = \\frac{1}{1+_e{-x}}$$"
      ],
      "metadata": {
        "id": "hZ1ebmhkg-oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return (1/(1+np.exp(-x.astype(float))))"
      ],
      "metadata": {
        "id": "liZOIhKfbnH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_h = sigmoid(z_h)\n",
        "print(f'a_h:\\n {a_h}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwCg2aR2bnKW",
        "outputId": "1dce8cc7-be63-43ec-9236-bc4efb1a8651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a_h:\n",
            " [[0.51776161 0.51842804]\n",
            " [0.61926872 0.54063517]\n",
            " [0.52584984 0.54924398]\n",
            " [0.54353151 0.56742727]\n",
            " [0.65948802 0.60689095]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll calculate the value of output layer by multiplying the value of hidden layer `a_h` with `w2`. Then, we'll pass the resultant value through a sigmoid function which in turn will return us the final value `a_o`.<br>\n",
        "$$z_o = \\sum_{i=1}^{} a_{h_i}w_{2_i}$$<br>\n",
        "$$a_o = sigmoid(z_o)$$\n"
      ],
      "metadata": {
        "id": "QXlcVF1npemb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_o=np.matmul(a_h,w2)\n",
        "a_o=sigmoid(z_o)\n",
        "print(f'a_o:\\n {a_o}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgYT7GbBtN03",
        "outputId": "0a8a6345-510d-410e-c345-299dba5b87a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a_o:\n",
            " [[0.62291649]\n",
            " [0.6455427 ]\n",
            " [0.62481343]\n",
            " [0.6288243 ]\n",
            " [0.65447578]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But, this is not our final output. We'll calculate the `error` from the difference between our ground truth `y` and `a_o`.<br>\n",
        "$$error, E_{a_o} = \\frac{1}{2} (a_o-y)^2$$"
      ],
      "metadata": {
        "id": "4YXskI5Ptm8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error = (0.5*(np.power((a_o-y),2)))\n",
        "print(f'error:\\n {error}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnXsQI2zva_s",
        "outputId": "9bdcc282-b0a2-40ff-e47b-5e130a0d467a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error:\n",
            " [[0.07109598840292192]\n",
            " [0.20836268866212068]\n",
            " [0.1951959110849411]\n",
            " [0.06888570122484873]\n",
            " [0.059693492247065494]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Back Propagation"
      ],
      "metadata": {
        "id": "oXEm4xtpsTfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Updating `w2`\n",
        "Back Propagation will start now. This means that in order to minimize the error that we have received, we will repeatedly update the weights of the `w1` and `w2` matrix back from the output layer and calculate the error. In this way we can reduce the error a lot at a time and predict the value which will be closer to the actual output.<br>\n",
        "\n",
        "So first we will find out how much change in the weights of `w2` will reduce our error. We will deduct the value of $\\frac {dE_{a_o}}{dw_2}$ from $w_2$.<br>\n",
        "$$w_2 = w_2 - learningRate×\\frac{dEa_o}{dw_2}$$.<br>\n",
        "From the chain rule of calculus, we can calculate the value of $\\frac {dE_{a_o}}{dw_2}$ as follows,<br>\n",
        "\n",
        "$$\\frac {dE_{a_o}}{dw_2} = \\frac {dE_{a_o}}{dz_o} × \\frac {d_{z_o}}{dw_2}$$<br>\n",
        "$$\\frac {dE_{a_o}}{dw_2} = \\frac {dE_{a_o}}{da_o} × \\frac {d{a_o}}{dz_o} × \\frac {d_{z_o}}{dw_2}$$<br>\n",
        "$$\\frac {dE_{a_o}}{da_o} = \\frac{d}{da_o}(\\frac{1}{2} (a_o-y)^2)=a_o-y$$<br>\n"
      ],
      "metadata": {
        "id": "bQQq5wTOvoZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dEdao = a_o-y\n",
        "print(f'dEdao:\\n {dEdao}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYCaVqiU2iIF",
        "outputId": "1f259e6c-7ced-49fd-cd2e-96fc46f2fd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dEdao:\n",
            " [[-0.37708351436497967]\n",
            " [0.6455426998458285]\n",
            " [0.6248134298891808]\n",
            " [-0.371175702935547]\n",
            " [-0.34552421694308344]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the second therm which is needed to calculate $\\frac {dE_{a_o}}{dw_2}$ is basically the derivative of the `sigmoid` function.<br>\n",
        "$\\frac{da_o}{dz_o} = \\frac{d}{dz_o}(\\frac{1}{1+_e{-z_o}})$<br>\n",
        "$\\frac{da_o}{dz_o} = \\frac{d}{dz_o}({1+_e{-z_o}})^{-1}$<br>\n",
        "$\\frac{da_o}{dz_o} = (-1)({1+_e{-z_o}})^{-2}(-e^{-z_o})$<br>\n",
        "....<br>....<br>\n",
        "$\\frac{da_o}{dz_o} =\\frac{1}{1+_e{-z_o}}×(1-\\frac{1}{1+_e{-z_o}}) = sigmoid(z_o)×(1-sigmoid(z_o))=a_o×(1-a_o)$"
      ],
      "metadata": {
        "id": "KmvyjNvc4EpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(x):\n",
        "    return x*(1-x)\n",
        "daozo = sigmoid_derivative(a_o)\n",
        "print(f'daozo:\\n {daozo}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px92HzlCaa9W",
        "outputId": "3f69f269-65c2-4506-a013-e01d3c40f10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "daozo:\n",
            " [[0.23489154]\n",
            " [0.22881732]\n",
            " [0.23442161]\n",
            " [0.2334043 ]\n",
            " [0.22613723]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last term,<br>\n",
        "$$\\frac{dz_o}{dw_2} = \\frac{d}{dw_2}(a_h×w_2) = a_h$$<br>\n",
        "Now, we have all the necessary information to calculate $\\frac {dE_{a_o}}{dw_2}$"
      ],
      "metadata": {
        "id": "zx9kODXbb9en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dEdw2 = np.matmul(a_h.T, (dEdao*daozo))\n",
        "print(f'dEdw2:\\n {dEdw2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erfBf0zXc3b4",
        "outputId": "80076e2d-986c-4512-9741-6a6fc227613b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dEdw2:\n",
            " [[0.024016055176844422]\n",
            " [0.017808025070625573]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll update the weight values of `w2` by subtracting $\\frac{dEa_o}{dw_2}$ from `w2`. But, for faster convergence, we'll multiply $\\frac{dEa_o}{dw_2}$ by `learning_rate = 3`."
      ],
      "metadata": {
        "id": "NtI8tqmdg1AT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 3\n",
        "w2 = w2 - learning_rate*dEdw2\n",
        "print(f'w2:\\n {w2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmwBH3Y_hfGE",
        "outputId": "dc67822b-7a4f-486e-e153-f99e7eaa49db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w2:\n",
            " [[0.8867064891529188]\n",
            " [-0.042739051137241156]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Updating `w1`\n",
        "Now we will go one more step backward. The updated value of `w1` will be, $$w_1 = w_1 - learningRate×\\frac{dEa_o}{dw_1}$$.<br>\n",
        "Now, using chain rule as before, we will calculate the value of $\\frac{dEa_o}{dw_1}$.<br>\n"
      ],
      "metadata": {
        "id": "ilbzTThZiWhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\frac{dEa_o}{dw_1} = \\frac{dEa_o}{dz_h}×\\frac{dz_h}{dw_1}$$\n",
        "$$\\frac{dEa_o}{dw_1} = \\frac{dEa_o}{da_h}×\\frac{da_h}{dz_h}×\\frac{dz_h}{dw_1}$$\n",
        "Since, there is no direct relationship between $dEa_o$ and $da_h$, we have to break them again using chain rule as follows.\n",
        "$$\\frac{dEa_o}{da_h} = \\frac{dEa_o}{dz_o}×\\frac{dz_o}{da_h} = \\frac{dEa_o}{da_o}×\\frac{da_o}{dz_o}×\\frac{dz_o}{da_h}$$\n",
        "But, we have already calculated the value of $\\frac{dEa_o}{da_o}×\\frac{da_o}{dz_o}$ while updating `w2`. So,\n",
        "$$\\frac{dz_o}{da_h} = \\frac{d}{da_h}(a_h×w_2) = w_2$$"
      ],
      "metadata": {
        "id": "WBKUIrkujPxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dEdzo = dEdao*daozo\n",
        "dEdah = np.matmul(dEdzo, w2.T)\n",
        "print(f'dEdah:\\n {dEdah}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASx8-jW-mPkl",
        "outputId": "00d0280c-8959-4c18-c7b5-583e916c39f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dEdah:\n",
            " [[-0.07853889803595969 0.0037855570253332916]\n",
            " [0.13097661447480044 -0.006313043033178743]\n",
            " [0.12987569442353758 -0.00625997893706066]\n",
            " [-0.07681893468171824 0.003702655182784095]\n",
            " [-0.06928360084380414 0.0033394538053559734]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully calculated the value of $\\frac{dEa_o}{da_h}$. As it is the derivative of sigmoid, $$\\frac{da_h}{dz_h} = a_h\\times(1-a_h)$$"
      ],
      "metadata": {
        "id": "DKosFkQInCIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dahdzh = sigmoid_derivative(a_h)\n",
        "print(f'dahdzh:\\n {dahdzh}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTSB98qynnzD",
        "outputId": "03977ba3-a69e-4397-90ee-0f9fa17f9282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dahdzh:\n",
            " [[0.24968453 0.24966041]\n",
            " [0.23577497 0.24834878]\n",
            " [0.24933179 0.24757503]\n",
            " [0.24810501 0.24545356]\n",
            " [0.22456357 0.23857433]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, for the last term to calculate $\\frac{dEa_o}{dw_1}$,$$\\frac{dz_h}{dw_1} = \\frac{d}{dw_1}(X×w_1) = X$$"
      ],
      "metadata": {
        "id": "26bA2etbj7x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dEdw1 = np.matmul(X.T, dEdah*dahdzh)\n",
        "print(f'dEdw1:\\n {dEdw1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn761PWHotVC",
        "outputId": "8f5d5e17-cdf0-4134-d618-7fc3f0224b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dEdw1:\n",
            " [[-0.0022355965018989784 0.00015572337054095282]\n",
            " [-0.05422768275790445 0.002650641554235369]\n",
            " [0.015322434669576898 -0.000771128617501693]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll update the weight values of `w1` by subtracting $\\frac{dEa_o}{dw_1}$ from `w1`."
      ],
      "metadata": {
        "id": "OGdMLx2ppu1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = w1-learning_rate*dEdw1\n",
        "print(f'w1:\\n {w1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiX97IrUp3W6",
        "outputId": "00421a86-f05e-4d30-b74f-79da4c63f137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1:\n",
            " [[0.11019843617606508 0.19714936780492834]\n",
            " [0.23375940249255672 0.06579365068896903]\n",
            " [0.44047818171662634 0.16521333153265494]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "davy_VOCqR23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X,w1,w2):\n",
        "    return sigmoid(np.matmul(sigmoid(np.matmul(X,w1)),w2))"
      ],
      "metadata": {
        "id": "a45S17lptzxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = predict(X, w1,w2)\n",
        "\n",
        "print(f'prediction probabilities:\\n {prediction}')\n",
        "print(f'prediction:\\n {np.round(prediction)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq38OHjbqXkw",
        "outputId": "5ed2dfe3-e850-40cb-c9c0-8f4af5609949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction probabilities:\n",
            " [[0.61606171]\n",
            " [0.62628627]\n",
            " [0.60928024]\n",
            " [0.62121178]\n",
            " [0.64175015]]\n",
            "prediction:\n",
            " [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "Let's run for 500 epochs and check whether the loss decreases or not. In the mean time, the prediction should get better."
      ],
      "metadata": {
        "id": "nD8La09qqwd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_np = data.to_numpy()\n",
        "X = data_np[:,[1,2,3]]\n",
        "y = data_np[:,4]\n",
        "y = np.atleast_2d(y).T\n",
        "\n",
        "w1 = np.random.random((3,2))\n",
        "w2 = np.random.random((2,1))\n",
        "\n",
        "epochs = 50\n",
        "learning_rate = 3\n",
        "\n",
        "for i in range(0, epochs):\n",
        "    z_h=np.matmul(X,w1)\n",
        "    a_h = sigmoid(z_h)\n",
        "    z_o=np.matmul(a_h,w2)\n",
        "    a_o=sigmoid(z_o)\n",
        "    error = (0.5*(np.power((a_o-y),2)))\n",
        "    print(f'error in epoch {i+1}: {np.sum(error)}')\n",
        "\n",
        "\n",
        "    dEdao = a_o-y\n",
        "    daozo = sigmoid_derivative(a_o)\n",
        "    dEdw2 = np.matmul(a_h.T, (dEdao*daozo))\n",
        "    learning_rate = 3\n",
        "    w2 = w2 - learning_rate*dEdw2\n",
        "\n",
        "    dEdzo = dEdao*daozo\n",
        "    dEdah = np.matmul(dEdzo, w2.T)\n",
        "    dahdzh = sigmoid_derivative(a_h)\n",
        "    dEdw1 = np.matmul(X.T, dEdah*dahdzh)\n",
        "    w1 = w1-learning_rate*dEdw1\n",
        "\n",
        "prediction = predict(X, w1, w2)\n",
        "\n",
        "print(f'prediction probabilities:\\n {prediction}')\n",
        "print(f'prediction:\\n {np.round(prediction)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUbD7hcxrFhI",
        "outputId": "adf72bab-d530-4b54-d467-b4e2fd244110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error in epoch 1: 0.6016890710790768\n",
            "error in epoch 2: 0.5917440463129184\n",
            "error in epoch 3: 0.584734625983793\n",
            "error in epoch 4: 0.5789404225898918\n",
            "error in epoch 5: 0.5738318819346266\n",
            "error in epoch 6: 0.5690971203519045\n",
            "error in epoch 7: 0.5645182844079516\n",
            "error in epoch 8: 0.5599272848427965\n",
            "error in epoch 9: 0.5551811832624735\n",
            "error in epoch 10: 0.5501464950460616\n",
            "error in epoch 11: 0.5446884603308002\n",
            "error in epoch 12: 0.5386634495293744\n",
            "error in epoch 13: 0.5319136710759208\n",
            "error in epoch 14: 0.5242639686720001\n",
            "error in epoch 15: 0.5155209605920476\n",
            "error in epoch 16: 0.5054751632870408\n",
            "error in epoch 17: 0.4939070629526213\n",
            "error in epoch 18: 0.48059829417590555\n",
            "error in epoch 19: 0.46534901927984246\n",
            "error in epoch 20: 0.4480020640379707\n",
            "error in epoch 21: 0.42847311815181244\n",
            "error in epoch 22: 0.40678422011087445\n",
            "error in epoch 23: 0.383094976969054\n",
            "error in epoch 24: 0.35772315443068564\n",
            "error in epoch 25: 0.3311446556995546\n",
            "error in epoch 26: 0.3039643717799636\n",
            "error in epoch 27: 0.27685585126175\n",
            "error in epoch 28: 0.25047910283742214\n",
            "error in epoch 29: 0.22539744196472716\n",
            "error in epoch 30: 0.20201798036328317\n",
            "error in epoch 31: 0.18057144047530455\n",
            "error in epoch 32: 0.16113036545229764\n",
            "error in epoch 33: 0.14365130696932543\n",
            "error in epoch 34: 0.12802283733718367\n",
            "error in epoch 35: 0.11410558196203674\n",
            "error in epoch 36: 0.1017576440446782\n",
            "error in epoch 37: 0.09084524444236165\n",
            "error in epoch 38: 0.08124288543571898\n",
            "error in epoch 39: 0.07282923074272114\n",
            "error in epoch 40: 0.06548386698724912\n",
            "error in epoch 41: 0.059087185913560276\n",
            "error in epoch 42: 0.05352286497289231\n",
            "error in epoch 43: 0.048681234337317233\n",
            "error in epoch 44: 0.04446208107540209\n",
            "error in epoch 45: 0.04077624786659771\n",
            "error in epoch 46: 0.03754603840163632\n",
            "error in epoch 47: 0.03470474709161997\n",
            "error in epoch 48: 0.032195676409790513\n",
            "error in epoch 49: 0.02997093175737395\n",
            "error in epoch 50: 0.027990184872354232\n",
            "prediction probabilities:\n",
            " [[0.9752543 ]\n",
            " [0.12808906]\n",
            " [0.13893209]\n",
            " [0.95986932]\n",
            " [0.87955385]]\n",
            "prediction:\n",
            " [[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tasks\n",
        "1. Implement a neural network model to categorize three species of Iris. The dataset can be found [here](https://www.kaggle.com/uciml/iris). Your neural network model should contain **two** hidden layers with as many neurons as you want. For this task, use of any libraries other than `numpy` and `pandas` is prohibited. Your training, validation and test set should have a ratio of 60:20:20. Finally, show the `accuracy` score along with two graphs - training & validation accuracy vs epoch, training & validation loss vs epoch.\n",
        "\n",
        "1. Implement a neural network model to categorize three species of Iris using **Keras** library from python. The dataset can be found [here](https://www.kaggle.com/uciml/iris). Your neural network model should contain **two** hidden layers with as many neurons as you want. For this task, use of any library is permissible. Your training, validation and test set should have a ratio of 60:20:20. Finally, show the `accuracy` score along with two graphs - training & validation accuracy vs epoch, training & validation loss vs epoch. This [link](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/) might help you implementing a neural network with **Keras**.\n",
        "\n",
        "1. For the task `2`, experiment with different number of hidden layers (*2, 4, 6*) to increase the accuracy score. Also show the effect of followings on overall performance: **different activation function (*relu, sigmoid, tanh*) for layers**, **different optimizers (*Adam, Adagrad, Adadelta*)**, and **various learning rates (*1, 0.1, 0.01*)**.\n",
        "<br>\n",
        "<br>\n",
        "*N.B.: Any additional experiment (such as, Early Stopping) with justification or training insights will contain bonus points.*\n",
        "    "
      ],
      "metadata": {
        "id": "IVlm_ftn9xXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q archive.zip"
      ],
      "metadata": {
        "id": "_S8vtCSlFdBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing of the dataset\n",
        "iris_data=pd.read_csv(\"Iris.csv\")\n",
        "iris_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNodI5NQHIGr",
        "outputId": "93db77c0-64a2-4117-dca8-1f69a69fb611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             150 non-null    int64  \n",
            " 1   SepalLengthCm  150 non-null    float64\n",
            " 2   SepalWidthCm   150 non-null    float64\n",
            " 3   PetalLengthCm  150 non-null    float64\n",
            " 4   PetalWidthCm   150 non-null    float64\n",
            " 5   Species        150 non-null    object \n",
            "dtypes: float64(4), int64(1), object(1)\n",
            "memory usage: 7.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "R87wfzDUIrZ9",
        "outputId": "800d45a0-44f1-4acd-98f7-21a4e6c596d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-70392816-d4e2-492c-b9db-e361be74d5e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70392816-d4e2-492c-b9db-e361be74d5e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70392816-d4e2-492c-b9db-e361be74d5e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70392816-d4e2-492c-b9db-e361be74d5e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzDnZMoCI1xb",
        "outputId": "cfab60fd-3bb0-4e14-c6fb-cd33f37bb4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id               0\n",
              "SepalLengthCm    0\n",
              "SepalWidthCm     0\n",
              "PetalLengthCm    0\n",
              "PetalWidthCm     0\n",
              "Species          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data[\"Species\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igleltqXJTOM",
        "outputId": "ec742274-91f0-4908-9edf-7d33f215e74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Iris-virginica     50\n",
              "Iris-setosa        50\n",
              "Iris-versicolor    50\n",
              "Name: Species, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data.drop(\"Id\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "pcKDNgb0J6xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data.replace({\"Iris-virginica\": 0,\"Iris-versicolor\":1,\"Iris-setosa\":2},inplace=True)\n",
        "iris_data[\"Iris-virginica\"]=iris_data['Species'].apply(lambda x: 1 if x ==0 else 0)\n",
        "iris_data[\"Iris-versicolor\"]=iris_data['Species'].apply(lambda x: 1 if x ==1 else 0)\n",
        "iris_data[\"Iris-setosa\"]=iris_data['Species'].apply(lambda x: 1 if x ==2 else 0)\n",
        "iris_data.drop(\"Species\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "kyjJQPQoKP9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data=iris_data.sample(frac=1).reset_index(drop=True)\n",
        "for col in iris_data.columns[:4]:\n",
        "  iris_data[col]=(iris_data[col]-iris_data[col].mean())/iris_data[col].std()"
      ],
      "metadata": {
        "id": "o3c31SeiKmXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Y0k_NOU9caqw",
        "outputId": "9cf5041d-8e54-4414-d63f-4e6fa6e7bbd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ecbed7c9-fbf7-4746-9885-bb2c072db39b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Iris-virginica</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-setosa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.139200</td>\n",
              "      <td>-0.124540</td>\n",
              "      <td>-1.336794</td>\n",
              "      <td>-1.308593</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.276066</td>\n",
              "      <td>0.106090</td>\n",
              "      <td>0.930239</td>\n",
              "      <td>1.181053</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.430722</td>\n",
              "      <td>-1.969583</td>\n",
              "      <td>0.420157</td>\n",
              "      <td>0.394849</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.139200</td>\n",
              "      <td>0.106090</td>\n",
              "      <td>-1.280118</td>\n",
              "      <td>-1.439627</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.293857</td>\n",
              "      <td>-0.355171</td>\n",
              "      <td>-0.089926</td>\n",
              "      <td>0.132781</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecbed7c9-fbf7-4746-9885-bb2c072db39b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecbed7c9-fbf7-4746-9885-bb2c072db39b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecbed7c9-fbf7-4746-9885-bb2c072db39b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  ...  Iris-versicolor  Iris-setosa\n",
              "0      -1.139200     -0.124540  ...                0            1\n",
              "1       1.276066      0.106090  ...                0            0\n",
              "2       0.430722     -1.969583  ...                1            0\n",
              "3      -1.139200      0.106090  ...                0            1\n",
              "4      -0.293857     -0.355171  ...                1            0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_test(data, test_ratio):\n",
        "   shuffled_indices = np.random.permutation(len(data))\n",
        "   test_set_size = int(len(data) * test_ratio)\n",
        "   test_indices = shuffled_indices[:test_set_size]\n",
        "   train_indices = shuffled_indices[test_set_size:]\n",
        "   return data.iloc[train_indices], data.iloc[test_indices]\n",
        "\n",
        "iris_data_train,iris_data_test =split_train_test(iris_data,0.2)\n",
        "iris_data_train,iris_data_valid=split_train_test(iris_data_train,0.2) "
      ],
      "metadata": {
        "id": "z3_qMyHKUu_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(iris_data_train.shape)\n",
        "print(iris_data_test.shape)\n",
        "print(iris_data_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAOes8Pdc1Et",
        "outputId": "919ee8a4-9d31-499f-dc85-a8438055db20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96, 7)\n",
            "(30, 7)\n",
            "(24, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Y_train=iris_data_train.iloc[:,4:]\n",
        "X_train=iris_data_train.iloc[:,0:4]\n",
        "\n",
        "Y_test=iris_data_test.iloc[:,4:]\n",
        "X_test=iris_data_test.iloc[:,0:4]\n",
        "\n",
        "Y_valid=iris_data_valid.iloc[:,4:]\n",
        "X_valid=iris_data_valid.iloc[:,0:4]"
      ],
      "metadata": {
        "id": "kxTEOXMcMYRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AHoTfbY_MIo6",
        "outputId": "448a86fe-72d2-457f-8af0-ae9614953271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-45cd087c-570f-4211-abb4-505f8bca5cc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>0.672249</td>\n",
              "      <td>-0.816431</td>\n",
              "      <td>0.873564</td>\n",
              "      <td>0.918985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0.672249</td>\n",
              "      <td>0.336720</td>\n",
              "      <td>0.873564</td>\n",
              "      <td>1.443121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>-1.380727</td>\n",
              "      <td>0.336720</td>\n",
              "      <td>-1.223442</td>\n",
              "      <td>-1.308593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>-0.535384</td>\n",
              "      <td>1.489872</td>\n",
              "      <td>-1.280118</td>\n",
              "      <td>-1.308593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>-0.173094</td>\n",
              "      <td>-1.277692</td>\n",
              "      <td>0.703536</td>\n",
              "      <td>1.050019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>-0.776911</td>\n",
              "      <td>-0.816431</td>\n",
              "      <td>0.080102</td>\n",
              "      <td>0.263815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-1.743017</td>\n",
              "      <td>0.336720</td>\n",
              "      <td>-1.393470</td>\n",
              "      <td>-1.308593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.430722</td>\n",
              "      <td>-1.969583</td>\n",
              "      <td>0.420157</td>\n",
              "      <td>0.394849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.913776</td>\n",
              "      <td>-0.355171</td>\n",
              "      <td>0.476833</td>\n",
              "      <td>0.132781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.173094</td>\n",
              "      <td>-0.355171</td>\n",
              "      <td>0.250129</td>\n",
              "      <td>0.132781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45cd087c-570f-4211-abb4-505f8bca5cc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45cd087c-570f-4211-abb4-505f8bca5cc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45cd087c-570f-4211-abb4-505f8bca5cc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
              "134       0.672249     -0.816431       0.873564      0.918985\n",
              "57        0.672249      0.336720       0.873564      1.443121\n",
              "107      -1.380727      0.336720      -1.223442     -1.308593\n",
              "109      -0.535384      1.489872      -1.280118     -1.308593\n",
              "103      -0.173094     -1.277692       0.703536      1.050019\n",
              "104      -0.776911     -0.816431       0.080102      0.263815\n",
              "23       -1.743017      0.336720      -1.393470     -1.308593\n",
              "2         0.430722     -1.969583       0.420157      0.394849\n",
              "6         0.913776     -0.355171       0.476833      0.132781\n",
              "11       -0.173094     -0.355171       0.250129      0.132781"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uJsmtv6ENhfy",
        "outputId": "b3fb211f-575f-4db3-ebc7-ac62eb042853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-60b032bc-66a3-4677-ba0a-6b5e7d05d85c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-virginica</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-setosa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60b032bc-66a3-4677-ba0a-6b5e7d05d85c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60b032bc-66a3-4677-ba0a-6b5e7d05d85c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60b032bc-66a3-4677-ba0a-6b5e7d05d85c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Iris-virginica  Iris-versicolor  Iris-setosa\n",
              "134               1                0            0\n",
              "57                1                0            0\n",
              "107               0                0            1\n",
              "109               0                0            1\n",
              "103               1                0            0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GATIslfPI097"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution: Task - 1"
      ],
      "metadata": {
        "id": "M-GWRdXfEADs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codes for Task 1\n",
        "iris_data_np = X_train.to_numpy()\n",
        "X = iris_data_np\n",
        "y = Y_train.to_numpy()\n",
        "\n",
        "X_t=X_valid.to_numpy()\n",
        "y_t=Y_valid.to_numpy()\n",
        "\n",
        "\n",
        "\n",
        "arr1=[]\n",
        "arr2=[]\n",
        "arr3=[]\n",
        "def predict_(X,w1,w2,w3):\n",
        "    return sigmoid(np.matmul(sigmoid(np.matmul(sigmoid(np.matmul(X,w1)),w2)),w3))\n",
        "train_error=[]\n",
        "validation_error=[] \n",
        "train_acc=[]\n",
        "validation_acc=[]\n",
        "def train(X,y,X_t,y_t,early_stopping=False):\n",
        "  number_of_neurons_in_input_layer = X_train.shape[1]\n",
        "  number_of_neurons_in_hidden_layer = 6\n",
        "  number_of_neurons_in_hidden_layer2 = 4\n",
        "  number_of_neurons_in_output_layer = 3\n",
        "\n",
        "  w1 = np.random.random((number_of_neurons_in_input_layer, number_of_neurons_in_hidden_layer))\n",
        "  w2 = np.random.random((number_of_neurons_in_hidden_layer, number_of_neurons_in_hidden_layer2))\n",
        "  w3 = np.random.random((number_of_neurons_in_hidden_layer2, number_of_neurons_in_output_layer))  \n",
        "  epochs = 1000\n",
        "  learning_rate = 0.1   \n",
        "  \n",
        "  for i in range(0, epochs):\n",
        "    arr1.append(w1.tolist())\n",
        "    arr2.append(w2.tolist())\n",
        "    arr3.append(w3.tolist())\n",
        "    z_h=np.matmul(X,w1)\n",
        "    a_h=sigmoid(z_h)\n",
        "    z_h2=np.matmul(a_h,w2)\n",
        "    a_h2=sigmoid(z_h2)\n",
        "    z_o=np.matmul(a_h2,w3)\n",
        "    a_o=sigmoid(z_o)\n",
        "\n",
        "\n",
        "    z_h_v=np.matmul(X_t,w1)\n",
        "    a_h_v=sigmoid(z_h_v)\n",
        "    z_h2_v=np.matmul(a_h_v,w2)\n",
        "    a_h2_v=sigmoid(z_h2_v)\n",
        "    z_o_v=np.matmul(a_h2_v,w3)\n",
        "    a_o_v=sigmoid(z_o_v)\n",
        "    error = (0.5*(np.power((a_o-y),2)))\n",
        "    valid_error=(0.5*(np.power((a_o_v-y_t),2)))\n",
        "    pred = predict_(X, w1, w2,w3)\n",
        "    pred_valid=predict_(X_t,w1,w2,w3)\n",
        "    acc=(np.sum(y==np.round(pred),axis=1)==3).sum()\n",
        "    valid_acc=(np.sum(y_t==np.round(pred_valid),axis=1)==3).sum()\n",
        "    print(f'error in epoch {i+1}: {np.sum(error)}')\n",
        "    print(f'\\t Accuracy in epoch {i+1}: {acc*100/len(X)}%')\n",
        "    print(f'\\nValidation error in epoch {i+1}: {np.sum(valid_error)}')\n",
        "    print(f'\\tValidation Accuracy in epoch {i+1}: {valid_acc*100/len(X_t)}%')\n",
        "    train_acc.append(acc*100/len(X))\n",
        "    validation_acc.append(valid_acc*100/len(X_t))\n",
        "    train_error.append(float(np.sum(error)))\n",
        "    validation_error.append(float(np.sum(valid_error)))\n",
        "    if(early_stopping==True):\n",
        "      if(i>0 and validation_error[i]-validation_error[i-1]>0.3):\n",
        "        break    \n",
        "    dEdao = a_o-y\n",
        "    daozo = sigmoid_derivative(a_o)\n",
        "    dEdw3 = np.matmul(a_h2.T, (dEdao*daozo))\n",
        "    \n",
        "    w3 = w3 - learning_rate*dEdw3\n",
        "\n",
        "    dEdzo = dEdao*daozo\n",
        "    dEdah2 = np.matmul(dEdzo, w3.T)\n",
        "    dahdzh2 = sigmoid_derivative(a_h2)\n",
        "    dEdw2 = np.matmul(a_h.T, dEdah2*dahdzh2)\n",
        "   \n",
        "    w2 = w2-learning_rate*dEdw2\n",
        "   \n",
        "    dEdzh = dEdah2*dahdzh2\n",
        "    dEdah = np.matmul(dEdzh, w2.T)\n",
        "    dahdzh = sigmoid_derivative(a_h)\n",
        "    dEdw1 = np.matmul(X.T, dEdah*dahdzh)\n",
        "   \n",
        "    w1 = w1-learning_rate*dEdw1\n",
        "  print(f'w1:\\n {w1}')\n",
        "  print(f'w2:\\n {w2}')\n",
        "  print(f'w3:\\n {w3}')   \n",
        "train(X,y,X_t,y_t,early_stopping=True)    \n",
        "  \n",
        "w1=np.array(arr1[-2])\n",
        "w2=np.array(arr2[-2])\n",
        "w3=np.array(arr3[-2])\n",
        "prediction = predict_(X, w1, w2,w3)\n",
        "\n",
        "print(f'prediction probabilities:\\n {prediction}')\n",
        "print(f'prediction:\\n {np.round(prediction)}')"
      ],
      "metadata": {
        "id": "vJcurzeEi8ww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c009d2d-cb11-4fb7-f069-f0b5eee6fd47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error in epoch 1: 60.35436999708253\n",
            "\t Accuracy in epoch 1: 0.0%\n",
            "\n",
            "Validation error in epoch 1: 14.906904627533692\n",
            "\tValidation Accuracy in epoch 1: 0.0%\n",
            "error in epoch 2: 35.281551903096954\n",
            "\t Accuracy in epoch 2: 33.333333333333336%\n",
            "\n",
            "Validation error in epoch 2: 8.442361617910079\n",
            "\tValidation Accuracy in epoch 2: 37.5%\n",
            "error in epoch 3: 32.108558356549516\n",
            "\t Accuracy in epoch 3: 0.0%\n",
            "\n",
            "Validation error in epoch 3: 8.087845037839212\n",
            "\tValidation Accuracy in epoch 3: 0.0%\n",
            "error in epoch 4: 31.817059418539394\n",
            "\t Accuracy in epoch 4: 0.0%\n",
            "\n",
            "Validation error in epoch 4: 7.927638549382747\n",
            "\tValidation Accuracy in epoch 4: 0.0%\n",
            "error in epoch 5: 31.8091994250059\n",
            "\t Accuracy in epoch 5: 0.0%\n",
            "\n",
            "Validation error in epoch 5: 7.918880150534633\n",
            "\tValidation Accuracy in epoch 5: 0.0%\n",
            "error in epoch 6: 31.80301496023136\n",
            "\t Accuracy in epoch 6: 0.0%\n",
            "\n",
            "Validation error in epoch 6: 7.918061455853572\n",
            "\tValidation Accuracy in epoch 6: 0.0%\n",
            "error in epoch 7: 31.796744939614378\n",
            "\t Accuracy in epoch 7: 0.0%\n",
            "\n",
            "Validation error in epoch 7: 7.916101500614301\n",
            "\tValidation Accuracy in epoch 7: 0.0%\n",
            "error in epoch 8: 31.790387921421633\n",
            "\t Accuracy in epoch 8: 0.0%\n",
            "\n",
            "Validation error in epoch 8: 7.914298909864096\n",
            "\tValidation Accuracy in epoch 8: 0.0%\n",
            "error in epoch 9: 31.783909283027644\n",
            "\t Accuracy in epoch 9: 0.0%\n",
            "\n",
            "Validation error in epoch 9: 7.912450898329073\n",
            "\tValidation Accuracy in epoch 9: 0.0%\n",
            "error in epoch 10: 31.777286841230346\n",
            "\t Accuracy in epoch 10: 0.0%\n",
            "\n",
            "Validation error in epoch 10: 7.910577504292332\n",
            "\tValidation Accuracy in epoch 10: 0.0%\n",
            "error in epoch 11: 31.770493184266662\n",
            "\t Accuracy in epoch 11: 0.0%\n",
            "\n",
            "Validation error in epoch 11: 7.908670737974112\n",
            "\tValidation Accuracy in epoch 11: 0.0%\n",
            "error in epoch 12: 31.763498159769718\n",
            "\t Accuracy in epoch 12: 0.0%\n",
            "\n",
            "Validation error in epoch 12: 7.906723790479361\n",
            "\tValidation Accuracy in epoch 12: 0.0%\n",
            "error in epoch 13: 31.756267443703045\n",
            "\t Accuracy in epoch 13: 0.0%\n",
            "\n",
            "Validation error in epoch 13: 7.904729455694474\n",
            "\tValidation Accuracy in epoch 13: 0.0%\n",
            "error in epoch 14: 31.748761736310364\n",
            "\t Accuracy in epoch 14: 0.0%\n",
            "\n",
            "Validation error in epoch 14: 7.902679219785419\n",
            "\tValidation Accuracy in epoch 14: 0.0%\n",
            "error in epoch 15: 31.74093555800155\n",
            "\t Accuracy in epoch 15: 0.0%\n",
            "\n",
            "Validation error in epoch 15: 7.900563372673563\n",
            "\tValidation Accuracy in epoch 15: 0.0%\n",
            "error in epoch 16: 31.732735787968416\n",
            "\t Accuracy in epoch 16: 0.0%\n",
            "\n",
            "Validation error in epoch 16: 7.898370565828328\n",
            "\tValidation Accuracy in epoch 16: 0.0%\n",
            "error in epoch 17: 31.724099805224355\n",
            "\t Accuracy in epoch 17: 0.0%\n",
            "\n",
            "Validation error in epoch 17: 7.896087445825243\n",
            "\tValidation Accuracy in epoch 17: 0.0%\n",
            "error in epoch 18: 31.7149531168382\n",
            "\t Accuracy in epoch 18: 0.0%\n",
            "\n",
            "Validation error in epoch 18: 7.893698127316927\n",
            "\tValidation Accuracy in epoch 18: 0.0%\n",
            "error in epoch 19: 31.705206297700066\n",
            "\t Accuracy in epoch 19: 0.0%\n",
            "\n",
            "Validation error in epoch 19: 7.891183526036833\n",
            "\tValidation Accuracy in epoch 19: 0.0%\n",
            "error in epoch 20: 31.694751002254698\n",
            "\t Accuracy in epoch 20: 0.0%\n",
            "\n",
            "Validation error in epoch 20: 7.8885204809482605\n",
            "\tValidation Accuracy in epoch 20: 0.0%\n",
            "error in epoch 21: 31.683454711226673\n",
            "\t Accuracy in epoch 21: 0.0%\n",
            "\n",
            "Validation error in epoch 21: 7.885680592543467\n",
            "\tValidation Accuracy in epoch 21: 0.0%\n",
            "error in epoch 22: 31.67115373565809\n",
            "\t Accuracy in epoch 22: 0.0%\n",
            "\n",
            "Validation error in epoch 22: 7.882628665821775\n",
            "\tValidation Accuracy in epoch 22: 0.0%\n",
            "error in epoch 23: 31.657643792988235\n",
            "\t Accuracy in epoch 23: 0.0%\n",
            "\n",
            "Validation error in epoch 23: 7.879320598575119\n",
            "\tValidation Accuracy in epoch 23: 0.0%\n",
            "error in epoch 24: 31.64266716093779\n",
            "\t Accuracy in epoch 24: 0.0%\n",
            "\n",
            "Validation error in epoch 24: 7.875700481264651\n",
            "\tValidation Accuracy in epoch 24: 0.0%\n",
            "error in epoch 25: 31.62589495051656\n",
            "\t Accuracy in epoch 25: 0.0%\n",
            "\n",
            "Validation error in epoch 25: 7.871696562508464\n",
            "\tValidation Accuracy in epoch 25: 0.0%\n",
            "error in epoch 26: 31.606902335664365\n",
            "\t Accuracy in epoch 26: 0.0%\n",
            "\n",
            "Validation error in epoch 26: 7.867215562093156\n",
            "\tValidation Accuracy in epoch 26: 0.0%\n",
            "error in epoch 27: 31.5851335048284\n",
            "\t Accuracy in epoch 27: 0.0%\n",
            "\n",
            "Validation error in epoch 27: 7.862134548148321\n",
            "\tValidation Accuracy in epoch 27: 0.0%\n",
            "error in epoch 28: 31.559851465830718\n",
            "\t Accuracy in epoch 28: 0.0%\n",
            "\n",
            "Validation error in epoch 28: 7.856289185447048\n",
            "\tValidation Accuracy in epoch 28: 0.0%\n",
            "error in epoch 29: 31.530065366728962\n",
            "\t Accuracy in epoch 29: 0.0%\n",
            "\n",
            "Validation error in epoch 29: 7.849456533146054\n",
            "\tValidation Accuracy in epoch 29: 0.0%\n",
            "error in epoch 30: 31.49442435936244\n",
            "\t Accuracy in epoch 30: 0.0%\n",
            "\n",
            "Validation error in epoch 30: 7.841329626252234\n",
            "\tValidation Accuracy in epoch 30: 0.0%\n",
            "error in epoch 31: 31.45106199245289\n",
            "\t Accuracy in epoch 31: 0.0%\n",
            "\n",
            "Validation error in epoch 31: 7.831479730478999\n",
            "\tValidation Accuracy in epoch 31: 0.0%\n",
            "error in epoch 32: 31.397369120782606\n",
            "\t Accuracy in epoch 32: 0.0%\n",
            "\n",
            "Validation error in epoch 32: 7.819300478293435\n",
            "\tValidation Accuracy in epoch 32: 0.0%\n",
            "error in epoch 33: 31.32966925804871\n",
            "\t Accuracy in epoch 33: 0.0%\n",
            "\n",
            "Validation error in epoch 33: 7.803926726617043\n",
            "\tValidation Accuracy in epoch 33: 0.0%\n",
            "error in epoch 34: 31.242778274169297\n",
            "\t Accuracy in epoch 34: 0.0%\n",
            "\n",
            "Validation error in epoch 34: 7.784122374584349\n",
            "\tValidation Accuracy in epoch 34: 0.0%\n",
            "error in epoch 35: 31.129478172610824\n",
            "\t Accuracy in epoch 35: 0.0%\n",
            "\n",
            "Validation error in epoch 35: 7.75814258782669\n",
            "\tValidation Accuracy in epoch 35: 0.0%\n",
            "error in epoch 36: 30.980083677121044\n",
            "\t Accuracy in epoch 36: 0.0%\n",
            "\n",
            "Validation error in epoch 36: 7.723612968924167\n",
            "\tValidation Accuracy in epoch 36: 0.0%\n",
            "error in epoch 37: 30.78261636931448\n",
            "\t Accuracy in epoch 37: 0.0%\n",
            "\n",
            "Validation error in epoch 37: 7.677555030161098\n",
            "\tValidation Accuracy in epoch 37: 0.0%\n",
            "error in epoch 38: 30.52457474458713\n",
            "\t Accuracy in epoch 38: 0.0%\n",
            "\n",
            "Validation error in epoch 38: 7.616815246700934\n",
            "\tValidation Accuracy in epoch 38: 0.0%\n",
            "error in epoch 39: 30.197223171671503\n",
            "\t Accuracy in epoch 39: 0.0%\n",
            "\n",
            "Validation error in epoch 39: 7.5391514209570225\n",
            "\tValidation Accuracy in epoch 39: 0.0%\n",
            "error in epoch 40: 29.801245333898535\n",
            "\t Accuracy in epoch 40: 0.0%\n",
            "\n",
            "Validation error in epoch 40: 7.444697481799203\n",
            "\tValidation Accuracy in epoch 40: 0.0%\n",
            "error in epoch 41: 29.34902255369723\n",
            "\t Accuracy in epoch 41: 0.0%\n",
            "\n",
            "Validation error in epoch 41: 7.336565846429144\n",
            "\tValidation Accuracy in epoch 41: 0.0%\n",
            "error in epoch 42: 28.859757315530302\n",
            "\t Accuracy in epoch 42: 0.0%\n",
            "\n",
            "Validation error in epoch 42: 7.219570189668971\n",
            "\tValidation Accuracy in epoch 42: 0.0%\n",
            "error in epoch 43: 28.351406672498552\n",
            "\t Accuracy in epoch 43: 0.0%\n",
            "\n",
            "Validation error in epoch 43: 7.0981299592016756\n",
            "\tValidation Accuracy in epoch 43: 0.0%\n",
            "error in epoch 44: 27.836427514184614\n",
            "\t Accuracy in epoch 44: 0.0%\n",
            "\n",
            "Validation error in epoch 44: 6.975223410138579\n",
            "\tValidation Accuracy in epoch 44: 0.0%\n",
            "error in epoch 45: 27.322334575167766\n",
            "\t Accuracy in epoch 45: 0.0%\n",
            "\n",
            "Validation error in epoch 45: 6.852591878895271\n",
            "\tValidation Accuracy in epoch 45: 0.0%\n",
            "error in epoch 46: 26.813852995485306\n",
            "\t Accuracy in epoch 46: 0.0%\n",
            "\n",
            "Validation error in epoch 46: 6.731309490095727\n",
            "\tValidation Accuracy in epoch 46: 0.0%\n",
            "error in epoch 47: 26.31450588008865\n",
            "\t Accuracy in epoch 47: 0.0%\n",
            "\n",
            "Validation error in epoch 47: 6.612180161457285\n",
            "\tValidation Accuracy in epoch 47: 0.0%\n",
            "error in epoch 48: 25.82731853411819\n",
            "\t Accuracy in epoch 48: 3.125%\n",
            "\n",
            "Validation error in epoch 48: 6.495904944196265\n",
            "\tValidation Accuracy in epoch 48: 0.0%\n",
            "error in epoch 49: 25.354981044161363\n",
            "\t Accuracy in epoch 49: 14.583333333333334%\n",
            "\n",
            "Validation error in epoch 49: 6.383114940728859\n",
            "\tValidation Accuracy in epoch 49: 12.5%\n",
            "error in epoch 50: 24.89979582304625\n",
            "\t Accuracy in epoch 50: 23.958333333333332%\n",
            "\n",
            "Validation error in epoch 50: 6.2743534075446235\n",
            "\tValidation Accuracy in epoch 50: 16.666666666666668%\n",
            "error in epoch 51: 24.463590413644262\n",
            "\t Accuracy in epoch 51: 29.166666666666668%\n",
            "\n",
            "Validation error in epoch 51: 6.170051627909325\n",
            "\tValidation Accuracy in epoch 51: 20.833333333333332%\n",
            "error in epoch 52: 24.047667543151974\n",
            "\t Accuracy in epoch 52: 30.208333333333332%\n",
            "\n",
            "Validation error in epoch 52: 6.07051563262138\n",
            "\tValidation Accuracy in epoch 52: 29.166666666666668%\n",
            "error in epoch 53: 23.652806915943724\n",
            "\t Accuracy in epoch 53: 30.208333333333332%\n",
            "\n",
            "Validation error in epoch 53: 5.975926582168077\n",
            "\tValidation Accuracy in epoch 53: 29.166666666666668%\n",
            "error in epoch 54: 23.279308907636562\n",
            "\t Accuracy in epoch 54: 31.25%\n",
            "\n",
            "Validation error in epoch 54: 5.886351784229545\n",
            "\tValidation Accuracy in epoch 54: 29.166666666666668%\n",
            "error in epoch 55: 22.92706368839697\n",
            "\t Accuracy in epoch 55: 31.25%\n",
            "\n",
            "Validation error in epoch 55: 5.801761908614495\n",
            "\tValidation Accuracy in epoch 55: 29.166666666666668%\n",
            "error in epoch 56: 22.595630697445266\n",
            "\t Accuracy in epoch 56: 31.25%\n",
            "\n",
            "Validation error in epoch 56: 5.722050508665019\n",
            "\tValidation Accuracy in epoch 56: 29.166666666666668%\n",
            "error in epoch 57: 22.2843175075291\n",
            "\t Accuracy in epoch 57: 31.25%\n",
            "\n",
            "Validation error in epoch 57: 5.647053118336723\n",
            "\tValidation Accuracy in epoch 57: 29.166666666666668%\n",
            "error in epoch 58: 21.992251385956934\n",
            "\t Accuracy in epoch 58: 31.25%\n",
            "\n",
            "Validation error in epoch 58: 5.576564328679492\n",
            "\tValidation Accuracy in epoch 58: 29.166666666666668%\n",
            "error in epoch 59: 21.718440269522926\n",
            "\t Accuracy in epoch 59: 31.25%\n",
            "\n",
            "Validation error in epoch 59: 5.510352120489525\n",
            "\tValidation Accuracy in epoch 59: 29.166666666666668%\n",
            "error in epoch 60: 21.461822216809544\n",
            "\t Accuracy in epoch 60: 31.25%\n",
            "\n",
            "Validation error in epoch 60: 5.448169308210894\n",
            "\tValidation Accuracy in epoch 60: 29.166666666666668%\n",
            "error in epoch 61: 21.221303820526014\n",
            "\t Accuracy in epoch 61: 31.25%\n",
            "\n",
            "Validation error in epoch 61: 5.3897622835223515\n",
            "\tValidation Accuracy in epoch 61: 29.166666666666668%\n",
            "error in epoch 62: 20.995788794324994\n",
            "\t Accuracy in epoch 62: 31.25%\n",
            "\n",
            "Validation error in epoch 62: 5.33487740566436\n",
            "\tValidation Accuracy in epoch 62: 29.166666666666668%\n",
            "error in epoch 63: 20.784198222794693\n",
            "\t Accuracy in epoch 63: 31.25%\n",
            "\n",
            "Validation error in epoch 63: 5.2832654325716035\n",
            "\tValidation Accuracy in epoch 63: 29.166666666666668%\n",
            "error in epoch 64: 20.585483960620767\n",
            "\t Accuracy in epoch 64: 31.25%\n",
            "\n",
            "Validation error in epoch 64: 5.234684369735309\n",
            "\tValidation Accuracy in epoch 64: 29.166666666666668%\n",
            "error in epoch 65: 20.398636513592777\n",
            "\t Accuracy in epoch 65: 31.25%\n",
            "\n",
            "Validation error in epoch 65: 5.188901064309148\n",
            "\tValidation Accuracy in epoch 65: 29.166666666666668%\n",
            "error in epoch 66: 20.22268851093\n",
            "\t Accuracy in epoch 66: 31.25%\n",
            "\n",
            "Validation error in epoch 66: 5.145691809779372\n",
            "\tValidation Accuracy in epoch 66: 29.166666666666668%\n",
            "error in epoch 67: 20.056714632285114\n",
            "\t Accuracy in epoch 67: 31.25%\n",
            "\n",
            "Validation error in epoch 67: 5.104842162255765\n",
            "\tValidation Accuracy in epoch 67: 29.166666666666668%\n",
            "error in epoch 68: 19.899828607679325\n",
            "\t Accuracy in epoch 68: 31.25%\n",
            "\n",
            "Validation error in epoch 68: 5.066146108095515\n",
            "\tValidation Accuracy in epoch 68: 29.166666666666668%\n",
            "error in epoch 69: 19.751177673837343\n",
            "\t Accuracy in epoch 69: 42.708333333333336%\n",
            "\n",
            "Validation error in epoch 69: 5.029404665698083\n",
            "\tValidation Accuracy in epoch 69: 37.5%\n",
            "error in epoch 70: 19.60993464697477\n",
            "\t Accuracy in epoch 70: 47.916666666666664%\n",
            "\n",
            "Validation error in epoch 70: 4.994423951671637\n",
            "\tValidation Accuracy in epoch 70: 54.166666666666664%\n",
            "error in epoch 71: 19.475287558146157\n",
            "\t Accuracy in epoch 71: 50.0%\n",
            "\n",
            "Validation error in epoch 71: 4.961012692493592\n",
            "\tValidation Accuracy in epoch 71: 58.333333333333336%\n",
            "error in epoch 72: 19.3464265938986\n",
            "\t Accuracy in epoch 72: 54.166666666666664%\n",
            "\n",
            "Validation error in epoch 72: 4.92897911762666\n",
            "\tValidation Accuracy in epoch 72: 58.333333333333336%\n",
            "error in epoch 73: 19.222527905764284\n",
            "\t Accuracy in epoch 73: 54.166666666666664%\n",
            "\n",
            "Validation error in epoch 73: 4.898127132525717\n",
            "\tValidation Accuracy in epoch 73: 58.333333333333336%\n",
            "error in epoch 74: 19.102733741197675\n",
            "\t Accuracy in epoch 74: 55.208333333333336%\n",
            "\n",
            "Validation error in epoch 74: 4.868251651564032\n",
            "\tValidation Accuracy in epoch 74: 58.333333333333336%\n",
            "error in epoch 75: 18.986128416857184\n",
            "\t Accuracy in epoch 75: 57.291666666666664%\n",
            "\n",
            "Validation error in epoch 75: 4.83913299955838\n",
            "\tValidation Accuracy in epoch 75: 58.333333333333336%\n",
            "error in epoch 76: 18.871710151336366\n",
            "\t Accuracy in epoch 76: 58.333333333333336%\n",
            "\n",
            "Validation error in epoch 76: 4.810530427367139\n",
            "\tValidation Accuracy in epoch 76: 58.333333333333336%\n",
            "error in epoch 77: 18.75836021503431\n",
            "\t Accuracy in epoch 77: 61.458333333333336%\n",
            "\n",
            "Validation error in epoch 77: 4.782175156085071\n",
            "\tValidation Accuracy in epoch 77: 62.5%\n",
            "error in epoch 78: 18.644814232091633\n",
            "\t Accuracy in epoch 78: 62.5%\n",
            "\n",
            "Validation error in epoch 78: 4.753764198865762\n",
            "\tValidation Accuracy in epoch 78: 66.66666666666667%\n",
            "error in epoch 79: 18.529647482182742\n",
            "\t Accuracy in epoch 79: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 79: 4.724957897912392\n",
            "\tValidation Accuracy in epoch 79: 66.66666666666667%\n",
            "error in epoch 80: 18.411298995890938\n",
            "\t Accuracy in epoch 80: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 80: 4.6953871575371275\n",
            "\tValidation Accuracy in epoch 80: 66.66666666666667%\n",
            "error in epoch 81: 18.288179314146745\n",
            "\t Accuracy in epoch 81: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 81: 4.6646809401123095\n",
            "\tValidation Accuracy in epoch 81: 66.66666666666667%\n",
            "error in epoch 82: 18.158927866881875\n",
            "\t Accuracy in epoch 82: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 82: 4.632529129417311\n",
            "\tValidation Accuracy in epoch 82: 66.66666666666667%\n",
            "error in epoch 83: 18.022880711627778\n",
            "\t Accuracy in epoch 83: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 83: 4.59879385592657\n",
            "\tValidation Accuracy in epoch 83: 66.66666666666667%\n",
            "error in epoch 84: 17.88071730602195\n",
            "\t Accuracy in epoch 84: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 84: 4.563659972675071\n",
            "\tValidation Accuracy in epoch 84: 66.66666666666667%\n",
            "error in epoch 85: 17.735023742084135\n",
            "\t Accuracy in epoch 85: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 85: 4.527761468194776\n",
            "\tValidation Accuracy in epoch 85: 66.66666666666667%\n",
            "error in epoch 86: 17.59025954600737\n",
            "\t Accuracy in epoch 86: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 86: 4.492164464369171\n",
            "\tValidation Accuracy in epoch 86: 66.66666666666667%\n",
            "error in epoch 87: 17.451753411158105\n",
            "\t Accuracy in epoch 87: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 87: 4.458123323221365\n",
            "\tValidation Accuracy in epoch 87: 66.66666666666667%\n",
            "error in epoch 88: 17.324098260303053\n",
            "\t Accuracy in epoch 88: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 88: 4.426701924093031\n",
            "\tValidation Accuracy in epoch 88: 66.66666666666667%\n",
            "error in epoch 89: 17.209949430667365\n",
            "\t Accuracy in epoch 89: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 89: 4.398497407965013\n",
            "\tValidation Accuracy in epoch 89: 66.66666666666667%\n",
            "error in epoch 90: 17.10985934414937\n",
            "\t Accuracy in epoch 90: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 90: 4.373611407299967\n",
            "\tValidation Accuracy in epoch 90: 66.66666666666667%\n",
            "error in epoch 91: 17.022886188985012\n",
            "\t Accuracy in epoch 91: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 91: 4.35180081613542\n",
            "\tValidation Accuracy in epoch 91: 66.66666666666667%\n",
            "error in epoch 92: 16.947359721443902\n",
            "\t Accuracy in epoch 92: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 92: 4.332659960636719\n",
            "\tValidation Accuracy in epoch 92: 66.66666666666667%\n",
            "error in epoch 93: 16.881437368339277\n",
            "\t Accuracy in epoch 93: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 93: 4.31574948810265\n",
            "\tValidation Accuracy in epoch 93: 66.66666666666667%\n",
            "error in epoch 94: 16.823398366435608\n",
            "\t Accuracy in epoch 94: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 94: 4.300662607526208\n",
            "\tValidation Accuracy in epoch 94: 66.66666666666667%\n",
            "error in epoch 95: 16.77175609093868\n",
            "\t Accuracy in epoch 95: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 95: 4.287049194227305\n",
            "\tValidation Accuracy in epoch 95: 66.66666666666667%\n",
            "error in epoch 96: 16.72527431197132\n",
            "\t Accuracy in epoch 96: 60.416666666666664%\n",
            "\n",
            "Validation error in epoch 96: 4.274618255283114\n",
            "\tValidation Accuracy in epoch 96: 62.5%\n",
            "error in epoch 97: 16.682942645474654\n",
            "\t Accuracy in epoch 97: 54.166666666666664%\n",
            "\n",
            "Validation error in epoch 97: 4.2631315224216415\n",
            "\tValidation Accuracy in epoch 97: 50.0%\n",
            "error in epoch 98: 16.643939728760763\n",
            "\t Accuracy in epoch 98: 46.875%\n",
            "\n",
            "Validation error in epoch 98: 4.252394580282593\n",
            "\tValidation Accuracy in epoch 98: 41.666666666666664%\n",
            "error in epoch 99: 16.607596681461096\n",
            "\t Accuracy in epoch 99: 41.666666666666664%\n",
            "\n",
            "Validation error in epoch 99: 4.242248268204211\n",
            "\tValidation Accuracy in epoch 99: 37.5%\n",
            "error in epoch 100: 16.573365386859336\n",
            "\t Accuracy in epoch 100: 41.666666666666664%\n",
            "\n",
            "Validation error in epoch 100: 4.232561298348531\n",
            "\tValidation Accuracy in epoch 100: 33.333333333333336%\n",
            "error in epoch 101: 16.540792545308047\n",
            "\t Accuracy in epoch 101: 36.458333333333336%\n",
            "\n",
            "Validation error in epoch 101: 4.223224252194335\n",
            "\tValidation Accuracy in epoch 101: 33.333333333333336%\n",
            "error in epoch 102: 16.509499048089705\n",
            "\t Accuracy in epoch 102: 35.416666666666664%\n",
            "\n",
            "Validation error in epoch 102: 4.214144822095002\n",
            "\tValidation Accuracy in epoch 102: 33.333333333333336%\n",
            "error in epoch 103: 16.47916379575615\n",
            "\t Accuracy in epoch 103: 35.416666666666664%\n",
            "\n",
            "Validation error in epoch 103: 4.205244082184624\n",
            "\tValidation Accuracy in epoch 103: 33.333333333333336%\n",
            "error in epoch 104: 16.449511061484394\n",
            "\t Accuracy in epoch 104: 35.416666666666664%\n",
            "\n",
            "Validation error in epoch 104: 4.196453575222957\n",
            "\tValidation Accuracy in epoch 104: 29.166666666666668%\n",
            "error in epoch 105: 16.420300616806397\n",
            "\t Accuracy in epoch 105: 34.375%\n",
            "\n",
            "Validation error in epoch 105: 4.187713032446155\n",
            "\tValidation Accuracy in epoch 105: 29.166666666666668%\n",
            "error in epoch 106: 16.3913199844025\n",
            "\t Accuracy in epoch 106: 34.375%\n",
            "\n",
            "Validation error in epoch 106: 4.178968578860449\n",
            "\tValidation Accuracy in epoch 106: 29.166666666666668%\n",
            "error in epoch 107: 16.362378318722936\n",
            "\t Accuracy in epoch 107: 34.375%\n",
            "\n",
            "Validation error in epoch 107: 4.170171308144663\n",
            "\tValidation Accuracy in epoch 107: 29.166666666666668%\n",
            "error in epoch 108: 16.333301527489933\n",
            "\t Accuracy in epoch 108: 34.375%\n",
            "\n",
            "Validation error in epoch 108: 4.161276137089388\n",
            "\tValidation Accuracy in epoch 108: 29.166666666666668%\n",
            "error in epoch 109: 16.303928334812547\n",
            "\t Accuracy in epoch 109: 34.375%\n",
            "\n",
            "Validation error in epoch 109: 4.152240869394696\n",
            "\tValidation Accuracy in epoch 109: 29.166666666666668%\n",
            "error in epoch 110: 16.27410705298123\n",
            "\t Accuracy in epoch 110: 34.375%\n",
            "\n",
            "Validation error in epoch 110: 4.1430254135823565\n",
            "\tValidation Accuracy in epoch 110: 29.166666666666668%\n",
            "error in epoch 111: 16.24369287921565\n",
            "\t Accuracy in epoch 111: 34.375%\n",
            "\n",
            "Validation error in epoch 111: 4.1335911108234\n",
            "\tValidation Accuracy in epoch 111: 29.166666666666668%\n",
            "error in epoch 112: 16.212545569732878\n",
            "\t Accuracy in epoch 112: 34.375%\n",
            "\n",
            "Validation error in epoch 112: 4.123900136643263\n",
            "\tValidation Accuracy in epoch 112: 29.166666666666668%\n",
            "error in epoch 113: 16.180527369982563\n",
            "\t Accuracy in epoch 113: 34.375%\n",
            "\n",
            "Validation error in epoch 113: 4.1139149466291585\n",
            "\tValidation Accuracy in epoch 113: 29.166666666666668%\n",
            "error in epoch 114: 16.147501099743394\n",
            "\t Accuracy in epoch 114: 34.375%\n",
            "\n",
            "Validation error in epoch 114: 4.103597741194481\n",
            "\tValidation Accuracy in epoch 114: 29.166666666666668%\n",
            "error in epoch 115: 16.113328307548887\n",
            "\t Accuracy in epoch 115: 34.375%\n",
            "\n",
            "Validation error in epoch 115: 4.09290992881674\n",
            "\tValidation Accuracy in epoch 115: 29.166666666666668%\n",
            "error in epoch 116: 16.077867422818912\n",
            "\t Accuracy in epoch 116: 34.375%\n",
            "\n",
            "Validation error in epoch 116: 4.081811571521953\n",
            "\tValidation Accuracy in epoch 116: 29.166666666666668%\n",
            "error in epoch 117: 16.04097184798976\n",
            "\t Accuracy in epoch 117: 34.375%\n",
            "\n",
            "Validation error in epoch 117: 4.070260801186194\n",
            "\tValidation Accuracy in epoch 117: 29.166666666666668%\n",
            "error in epoch 118: 16.002487948343703\n",
            "\t Accuracy in epoch 118: 34.375%\n",
            "\n",
            "Validation error in epoch 118: 4.058213200759375\n",
            "\tValidation Accuracy in epoch 118: 33.333333333333336%\n",
            "error in epoch 119: 15.962252915120303\n",
            "\t Accuracy in epoch 119: 35.416666666666664%\n",
            "\n",
            "Validation error in epoch 119: 4.045621150890275\n",
            "\tValidation Accuracy in epoch 119: 33.333333333333336%\n",
            "error in epoch 120: 15.920092498202596\n",
            "\t Accuracy in epoch 120: 41.666666666666664%\n",
            "\n",
            "Validation error in epoch 120: 4.032433149524977\n",
            "\tValidation Accuracy in epoch 120: 37.5%\n",
            "error in epoch 121: 15.875818627871567\n",
            "\t Accuracy in epoch 121: 59.375%\n",
            "\n",
            "Validation error in epoch 121: 4.018593119525258\n",
            "\tValidation Accuracy in epoch 121: 58.333333333333336%\n",
            "error in epoch 122: 15.82922696983157\n",
            "\t Accuracy in epoch 122: 62.5%\n",
            "\n",
            "Validation error in epoch 122: 4.004039726714622\n",
            "\tValidation Accuracy in epoch 122: 62.5%\n",
            "error in epoch 123: 15.78009448254746\n",
            "\t Accuracy in epoch 123: 62.5%\n",
            "\n",
            "Validation error in epoch 123: 3.98870573748682\n",
            "\tValidation Accuracy in epoch 123: 62.5%\n",
            "error in epoch 124: 15.728177069544817\n",
            "\t Accuracy in epoch 124: 62.5%\n",
            "\n",
            "Validation error in epoch 124: 3.972517450839124\n",
            "\tValidation Accuracy in epoch 124: 62.5%\n",
            "error in epoch 125: 15.673207440903164\n",
            "\t Accuracy in epoch 125: 62.5%\n",
            "\n",
            "Validation error in epoch 125: 3.955394244403319\n",
            "\tValidation Accuracy in epoch 125: 62.5%\n",
            "error in epoch 126: 15.61489331792691\n",
            "\t Accuracy in epoch 126: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 126: 3.9372482782096467\n",
            "\tValidation Accuracy in epoch 126: 62.5%\n",
            "error in epoch 127: 15.55291613429902\n",
            "\t Accuracy in epoch 127: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 127: 3.9179844044986973\n",
            "\tValidation Accuracy in epoch 127: 62.5%\n",
            "error in epoch 128: 15.486930408153333\n",
            "\t Accuracy in epoch 128: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 128: 3.897500338195748\n",
            "\tValidation Accuracy in epoch 128: 62.5%\n",
            "error in epoch 129: 15.416563984618904\n",
            "\t Accuracy in epoch 129: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 129: 3.8756871519858906\n",
            "\tValidation Accuracy in epoch 129: 62.5%\n",
            "error in epoch 130: 15.341419378143865\n",
            "\t Accuracy in epoch 130: 63.541666666666664%\n",
            "\n",
            "Validation error in epoch 130: 3.852430173119731\n",
            "\tValidation Accuracy in epoch 130: 62.5%\n",
            "error in epoch 131: 15.26107647568045\n",
            "\t Accuracy in epoch 131: 64.58333333333333%\n",
            "\n",
            "Validation error in epoch 131: 3.827610376002812\n",
            "\tValidation Accuracy in epoch 131: 62.5%\n",
            "error in epoch 132: 15.17509688811261\n",
            "\t Accuracy in epoch 132: 64.58333333333333%\n",
            "\n",
            "Validation error in epoch 132: 3.801106383647566\n",
            "\tValidation Accuracy in epoch 132: 62.5%\n",
            "error in epoch 133: 15.083030244823393\n",
            "\t Accuracy in epoch 133: 64.58333333333333%\n",
            "\n",
            "Validation error in epoch 133: 3.7727972085831647\n",
            "\tValidation Accuracy in epoch 133: 70.83333333333333%\n",
            "error in epoch 134: 14.984422696306805\n",
            "\t Accuracy in epoch 134: 64.58333333333333%\n",
            "\n",
            "Validation error in epoch 134: 3.742565873759474\n",
            "\tValidation Accuracy in epoch 134: 70.83333333333333%\n",
            "error in epoch 135: 14.878827800568242\n",
            "\t Accuracy in epoch 135: 65.625%\n",
            "\n",
            "Validation error in epoch 135: 3.710304047407236\n",
            "\tValidation Accuracy in epoch 135: 70.83333333333333%\n",
            "error in epoch 136: 14.765819801335681\n",
            "\t Accuracy in epoch 136: 66.66666666666667%\n",
            "\n",
            "Validation error in epoch 136: 3.6759177907835516\n",
            "\tValidation Accuracy in epoch 136: 70.83333333333333%\n",
            "error in epoch 137: 14.645009050688316\n",
            "\t Accuracy in epoch 137: 70.83333333333333%\n",
            "\n",
            "Validation error in epoch 137: 3.63933444003491\n",
            "\tValidation Accuracy in epoch 137: 70.83333333333333%\n",
            "error in epoch 138: 14.516058996263364\n",
            "\t Accuracy in epoch 138: 71.875%\n",
            "\n",
            "Validation error in epoch 138: 3.6005105091885876\n",
            "\tValidation Accuracy in epoch 138: 75.0%\n",
            "error in epoch 139: 14.378703781957999\n",
            "\t Accuracy in epoch 139: 73.95833333333333%\n",
            "\n",
            "Validation error in epoch 139: 3.559440302520273\n",
            "\tValidation Accuracy in epoch 139: 75.0%\n",
            "error in epoch 140: 14.232765167787353\n",
            "\t Accuracy in epoch 140: 75.0%\n",
            "\n",
            "Validation error in epoch 140: 3.5161646676137175\n",
            "\tValidation Accuracy in epoch 140: 79.16666666666667%\n",
            "error in epoch 141: 14.078167244205217\n",
            "\t Accuracy in epoch 141: 76.04166666666667%\n",
            "\n",
            "Validation error in epoch 141: 3.4707790356298975\n",
            "\tValidation Accuracy in epoch 141: 79.16666666666667%\n",
            "error in epoch 142: 13.914947379742198\n",
            "\t Accuracy in epoch 142: 82.29166666666667%\n",
            "\n",
            "Validation error in epoch 142: 3.423439642466978\n",
            "\tValidation Accuracy in epoch 142: 83.33333333333333%\n",
            "error in epoch 143: 13.743262049007619\n",
            "\t Accuracy in epoch 143: 82.29166666666667%\n",
            "\n",
            "Validation error in epoch 143: 3.374366688163283\n",
            "\tValidation Accuracy in epoch 143: 83.33333333333333%\n",
            "error in epoch 144: 13.563386643753168\n",
            "\t Accuracy in epoch 144: 82.29166666666667%\n",
            "\n",
            "Validation error in epoch 144: 3.3238432620251994\n",
            "\tValidation Accuracy in epoch 144: 83.33333333333333%\n",
            "error in epoch 145: 13.37570902883626\n",
            "\t Accuracy in epoch 145: 82.29166666666667%\n",
            "\n",
            "Validation error in epoch 145: 3.2722092015537463\n",
            "\tValidation Accuracy in epoch 145: 83.33333333333333%\n",
            "error in epoch 146: 13.18071739398136\n",
            "\t Accuracy in epoch 146: 82.29166666666667%\n",
            "\n",
            "Validation error in epoch 146: 3.2198496687325857\n",
            "\tValidation Accuracy in epoch 146: 83.33333333333333%\n",
            "error in epoch 147: 12.978983784500349\n",
            "\t Accuracy in epoch 147: 84.375%\n",
            "\n",
            "Validation error in epoch 147: 3.1671790397554105\n",
            "\tValidation Accuracy in epoch 147: 83.33333333333333%\n",
            "error in epoch 148: 12.771145467346242\n",
            "\t Accuracy in epoch 148: 85.41666666666667%\n",
            "\n",
            "Validation error in epoch 148: 3.114621553209738\n",
            "\tValidation Accuracy in epoch 148: 87.5%\n",
            "error in epoch 149: 12.55788686346662\n",
            "\t Accuracy in epoch 149: 84.375%\n",
            "\n",
            "Validation error in epoch 149: 3.0625908329635068\n",
            "\tValidation Accuracy in epoch 149: 87.5%\n",
            "error in epoch 150: 12.339924960703001\n",
            "\t Accuracy in epoch 150: 87.5%\n",
            "\n",
            "Validation error in epoch 150: 3.0114706877002533\n",
            "\tValidation Accuracy in epoch 150: 87.5%\n",
            "error in epoch 151: 12.11800069622767\n",
            "\t Accuracy in epoch 151: 88.54166666666667%\n",
            "\n",
            "Validation error in epoch 151: 2.961599366206442\n",
            "\tValidation Accuracy in epoch 151: 87.5%\n",
            "error in epoch 152: 11.892877616074411\n",
            "\t Accuracy in epoch 152: 88.54166666666667%\n",
            "\n",
            "Validation error in epoch 152: 2.9132587441280426\n",
            "\tValidation Accuracy in epoch 152: 87.5%\n",
            "error in epoch 153: 11.665347238614965\n",
            "\t Accuracy in epoch 153: 88.54166666666667%\n",
            "\n",
            "Validation error in epoch 153: 2.866668926734679\n",
            "\tValidation Accuracy in epoch 153: 87.5%\n",
            "error in epoch 154: 11.436238333771495\n",
            "\t Accuracy in epoch 154: 88.54166666666667%\n",
            "\n",
            "Validation error in epoch 154: 2.821987770560224\n",
            "\tValidation Accuracy in epoch 154: 87.5%\n",
            "error in epoch 155: 11.20642543970295\n",
            "\t Accuracy in epoch 155: 89.58333333333333%\n",
            "\n",
            "Validation error in epoch 155: 2.7793141423525016\n",
            "\tValidation Accuracy in epoch 155: 87.5%\n",
            "error in epoch 156: 10.976831149943667\n",
            "\t Accuracy in epoch 156: 90.625%\n",
            "\n",
            "Validation error in epoch 156: 2.738693510343351\n",
            "\tValidation Accuracy in epoch 156: 87.5%\n",
            "error in epoch 157: 10.74841759547533\n",
            "\t Accuracy in epoch 157: 90.625%\n",
            "\n",
            "Validation error in epoch 157: 2.7001246794988307\n",
            "\tValidation Accuracy in epoch 157: 87.5%\n",
            "error in epoch 158: 10.522165158776495\n",
            "\t Accuracy in epoch 158: 90.625%\n",
            "\n",
            "Validation error in epoch 158: 2.6635669518473994\n",
            "\tValidation Accuracy in epoch 158: 87.5%\n",
            "error in epoch 159: 10.299040103439658\n",
            "\t Accuracy in epoch 159: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 159: 2.62894745120269\n",
            "\tValidation Accuracy in epoch 159: 87.5%\n",
            "error in epoch 160: 10.079956212743735\n",
            "\t Accuracy in epoch 160: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 160: 2.596168583349152\n",
            "\tValidation Accuracy in epoch 160: 87.5%\n",
            "error in epoch 161: 9.865737375513824\n",
            "\t Accuracy in epoch 161: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 161: 2.5651155458262007\n",
            "\tValidation Accuracy in epoch 161: 87.5%\n",
            "error in epoch 162: 9.657087634619336\n",
            "\t Accuracy in epoch 162: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 162: 2.5356635689596168\n",
            "\tValidation Accuracy in epoch 162: 87.5%\n",
            "error in epoch 163: 9.454572843013777\n",
            "\t Accuracy in epoch 163: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 163: 2.5076843682788965\n",
            "\tValidation Accuracy in epoch 163: 87.5%\n",
            "error in epoch 164: 9.25861489365786\n",
            "\t Accuracy in epoch 164: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 164: 2.481051281274791\n",
            "\tValidation Accuracy in epoch 164: 87.5%\n",
            "error in epoch 165: 9.06949678188849\n",
            "\t Accuracy in epoch 165: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 165: 2.455642772927966\n",
            "\tValidation Accuracy in epoch 165: 87.5%\n",
            "error in epoch 166: 8.887375284995418\n",
            "\t Accuracy in epoch 166: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 166: 2.431344317657037\n",
            "\tValidation Accuracy in epoch 166: 87.5%\n",
            "error in epoch 167: 8.712297841016122\n",
            "\t Accuracy in epoch 167: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 167: 2.408048951231242\n",
            "\tValidation Accuracy in epoch 167: 83.33333333333333%\n",
            "error in epoch 168: 8.544220830539793\n",
            "\t Accuracy in epoch 168: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 168: 2.385656935861552\n",
            "\tValidation Accuracy in epoch 168: 83.33333333333333%\n",
            "error in epoch 169: 8.383027373742284\n",
            "\t Accuracy in epoch 169: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 169: 2.3640749818342144\n",
            "\tValidation Accuracy in epoch 169: 83.33333333333333%\n",
            "error in epoch 170: 8.228543580145079\n",
            "\t Accuracy in epoch 170: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 170: 2.3432153687301476\n",
            "\tValidation Accuracy in epoch 170: 83.33333333333333%\n",
            "error in epoch 171: 8.080552782039977\n",
            "\t Accuracy in epoch 171: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 171: 2.3229951745263917\n",
            "\tValidation Accuracy in epoch 171: 87.5%\n",
            "error in epoch 172: 7.938807646033525\n",
            "\t Accuracy in epoch 172: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 172: 2.30333570123512\n",
            "\tValidation Accuracy in epoch 172: 87.5%\n",
            "error in epoch 173: 7.803040252914816\n",
            "\t Accuracy in epoch 173: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 173: 2.2841621038007127\n",
            "\tValidation Accuracy in epoch 173: 87.5%\n",
            "error in epoch 174: 7.672970328880286\n",
            "\t Accuracy in epoch 174: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 174: 2.265403185818405\n",
            "\tValidation Accuracy in epoch 174: 87.5%\n",
            "error in epoch 175: 7.548311847263684\n",
            "\t Accuracy in epoch 175: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 175: 2.2469913117028777\n",
            "\tValidation Accuracy in epoch 175: 87.5%\n",
            "error in epoch 176: 7.42877822641764\n",
            "\t Accuracy in epoch 176: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 176: 2.228862388111145\n",
            "\tValidation Accuracy in epoch 176: 87.5%\n",
            "error in epoch 177: 7.314086340529804\n",
            "\t Accuracy in epoch 177: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 177: 2.2109558783826344\n",
            "\tValidation Accuracy in epoch 177: 87.5%\n",
            "error in epoch 178: 7.203959543229929\n",
            "\t Accuracy in epoch 178: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 178: 2.193214825744718\n",
            "\tValidation Accuracy in epoch 178: 87.5%\n",
            "error in epoch 179: 7.098129882845204\n",
            "\t Accuracy in epoch 179: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 179: 2.175585871939118\n",
            "\tValidation Accuracy in epoch 179: 87.5%\n",
            "error in epoch 180: 6.99633966555115\n",
            "\t Accuracy in epoch 180: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 180: 2.1580192648810974\n",
            "\tValidation Accuracy in epoch 180: 87.5%\n",
            "error in epoch 181: 6.898342500103478\n",
            "\t Accuracy in epoch 181: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 181: 2.140468855153473\n",
            "\tValidation Accuracy in epoch 181: 87.5%\n",
            "error in epoch 182: 6.8039039364446765\n",
            "\t Accuracy in epoch 182: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 182: 2.122892081557461\n",
            "\tValidation Accuracy in epoch 182: 87.5%\n",
            "error in epoch 183: 6.712801790959716\n",
            "\t Accuracy in epoch 183: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 183: 2.1052499509945837\n",
            "\tValidation Accuracy in epoch 183: 87.5%\n",
            "error in epoch 184: 6.6248262338764725\n",
            "\t Accuracy in epoch 184: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 184: 2.087507010906964\n",
            "\tValidation Accuracy in epoch 184: 87.5%\n",
            "error in epoch 185: 6.5397796993762185\n",
            "\t Accuracy in epoch 185: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 185: 2.069631324539031\n",
            "\tValidation Accuracy in epoch 185: 87.5%\n",
            "error in epoch 186: 6.457476666344936\n",
            "\t Accuracy in epoch 186: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 186: 2.0515944359205087\n",
            "\tValidation Accuracy in epoch 186: 87.5%\n",
            "error in epoch 187: 6.377743347163038\n",
            "\t Accuracy in epoch 187: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 187: 2.033371350901555\n",
            "\tValidation Accuracy in epoch 187: 87.5%\n",
            "error in epoch 188: 6.300417313312671\n",
            "\t Accuracy in epoch 188: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 188: 2.0149404870986505\n",
            "\tValidation Accuracy in epoch 188: 87.5%\n",
            "error in epoch 189: 6.225347079549506\n",
            "\t Accuracy in epoch 189: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 189: 1.9962836759605112\n",
            "\tValidation Accuracy in epoch 189: 87.5%\n",
            "error in epoch 190: 6.152391662845718\n",
            "\t Accuracy in epoch 190: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 190: 1.9773860619057428\n",
            "\tValidation Accuracy in epoch 190: 87.5%\n",
            "error in epoch 191: 6.081420127764844\n",
            "\t Accuracy in epoch 191: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 191: 1.9582361759085969\n",
            "\tValidation Accuracy in epoch 191: 87.5%\n",
            "error in epoch 192: 6.012311126676386\n",
            "\t Accuracy in epoch 192: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 192: 1.9388256689357548\n",
            "\tValidation Accuracy in epoch 192: 87.5%\n",
            "error in epoch 193: 5.944952440189443\n",
            "\t Accuracy in epoch 193: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 193: 1.9191496463751685\n",
            "\tValidation Accuracy in epoch 193: 87.5%\n",
            "error in epoch 194: 5.879240521847882\n",
            "\t Accuracy in epoch 194: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 194: 1.8992058540759622\n",
            "\tValidation Accuracy in epoch 194: 87.5%\n",
            "error in epoch 195: 5.8150800484763145\n",
            "\t Accuracy in epoch 195: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 195: 1.8789959686340665\n",
            "\tValidation Accuracy in epoch 195: 87.5%\n",
            "error in epoch 196: 5.752383478649477\n",
            "\t Accuracy in epoch 196: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 196: 1.8585228912227678\n",
            "\tValidation Accuracy in epoch 196: 87.5%\n",
            "error in epoch 197: 5.691070617295312\n",
            "\t Accuracy in epoch 197: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 197: 1.8377955501994867\n",
            "\tValidation Accuracy in epoch 197: 87.5%\n",
            "error in epoch 198: 5.631068190756855\n",
            "\t Accuracy in epoch 198: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 198: 1.8168193567351283\n",
            "\tValidation Accuracy in epoch 198: 87.5%\n",
            "error in epoch 199: 5.572309424438236\n",
            "\t Accuracy in epoch 199: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 199: 1.7956141312200935\n",
            "\tValidation Accuracy in epoch 199: 87.5%\n",
            "error in epoch 200: 5.514733636538011\n",
            "\t Accuracy in epoch 200: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 200: 1.7741788779686214\n",
            "\tValidation Accuracy in epoch 200: 87.5%\n",
            "error in epoch 201: 5.4582858232502165\n",
            "\t Accuracy in epoch 201: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 201: 1.7525600972643038\n",
            "\tValidation Accuracy in epoch 201: 87.5%\n",
            "error in epoch 202: 5.402916279532402\n",
            "\t Accuracy in epoch 202: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 202: 1.7307165784285412\n",
            "\tValidation Accuracy in epoch 202: 87.5%\n",
            "error in epoch 203: 5.348580178353567\n",
            "\t Accuracy in epoch 203: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 203: 1.7087876430722426\n",
            "\tValidation Accuracy in epoch 203: 87.5%\n",
            "error in epoch 204: 5.29523725447728\n",
            "\t Accuracy in epoch 204: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 204: 1.6865542410265149\n",
            "\tValidation Accuracy in epoch 204: 87.5%\n",
            "error in epoch 205: 5.242851364946604\n",
            "\t Accuracy in epoch 205: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 205: 1.6645299116568295\n",
            "\tValidation Accuracy in epoch 205: 87.5%\n",
            "error in epoch 206: 5.191390479929394\n",
            "\t Accuracy in epoch 206: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 206: 1.6417288370006315\n",
            "\tValidation Accuracy in epoch 206: 87.5%\n",
            "error in epoch 207: 5.1408267744239975\n",
            "\t Accuracy in epoch 207: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 207: 1.6202756631667987\n",
            "\tValidation Accuracy in epoch 207: 87.5%\n",
            "error in epoch 208: 5.091140459335747\n",
            "\t Accuracy in epoch 208: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 208: 1.5957869870350903\n",
            "\tValidation Accuracy in epoch 208: 87.5%\n",
            "error in epoch 209: 5.0423353029056575\n",
            "\t Accuracy in epoch 209: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 209: 1.5776519525432566\n",
            "\tValidation Accuracy in epoch 209: 87.5%\n",
            "error in epoch 210: 4.994521903662962\n",
            "\t Accuracy in epoch 210: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 210: 1.5458496588370245\n",
            "\tValidation Accuracy in epoch 210: 87.5%\n",
            "error in epoch 211: 4.94831083850266\n",
            "\t Accuracy in epoch 211: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 211: 1.5440151183441728\n",
            "\tValidation Accuracy in epoch 211: 87.5%\n",
            "error in epoch 212: 4.906866152681845\n",
            "\t Accuracy in epoch 212: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 212: 1.4774847365085535\n",
            "\tValidation Accuracy in epoch 212: 87.5%\n",
            "error in epoch 213: 4.88578671312165\n",
            "\t Accuracy in epoch 213: 93.75%\n",
            "\n",
            "Validation error in epoch 213: 1.55984025967716\n",
            "\tValidation Accuracy in epoch 213: 87.5%\n",
            "error in epoch 214: 4.971790783757554\n",
            "\t Accuracy in epoch 214: 92.70833333333333%\n",
            "\n",
            "Validation error in epoch 214: 1.3388398433646935\n",
            "\tValidation Accuracy in epoch 214: 91.66666666666667%\n",
            "error in epoch 215: 5.560517396574803\n",
            "\t Accuracy in epoch 215: 96.875%\n",
            "\n",
            "Validation error in epoch 215: 1.919588266295782\n",
            "\tValidation Accuracy in epoch 215: 87.5%\n",
            "w1:\n",
            " [[ 1.12579864 -0.04724313  0.86993687 -0.10589004  0.54738693  0.14637531]\n",
            " [-0.64889724  0.2763899  -0.92776543  0.12873307  0.02701357 -1.8412682 ]\n",
            " [ 1.47542391  0.70140328  1.51858553  0.79821913 -0.70065633  2.06228729]\n",
            " [ 0.85568339  1.70912044  0.89776982  1.67411236 -1.85878539  1.42585763]]\n",
            "w2:\n",
            " [[-0.39110338  1.51123932  0.33727458 -0.35166893]\n",
            " [-0.12081224  0.6167168   0.45274404  1.39654723]\n",
            " [-1.16037622  1.25681724  0.74109464 -0.20186757]\n",
            " [-1.50301837  0.83073298  0.66427878  1.57305483]\n",
            " [ 2.64985914 -0.50827506  0.6188491  -6.60318414]\n",
            " [-2.60697466  2.36500193  0.80323478 -0.76507799]]\n",
            "w3:\n",
            " [[-5.44411046 -4.00096615  6.02213103]\n",
            " [-1.79244071  2.62607988 -2.10451005]\n",
            " [-0.80699315  0.15555519 -1.55442634]\n",
            " [ 5.07027993 -5.23338537 -1.59606885]]\n",
            "prediction probabilities:\n",
            " [[0.80699829 0.19824286 0.00846416]\n",
            " [0.87089998 0.13196149 0.00726273]\n",
            " [0.00206774 0.07192008 0.97424835]\n",
            " [0.00201613 0.06991668 0.97515818]\n",
            " [0.84225772 0.16194799 0.00785607]\n",
            " [0.32683641 0.64798332 0.02070539]\n",
            " [0.00208005 0.07072626 0.97478814]\n",
            " [0.32808198 0.68248608 0.01728509]\n",
            " [0.13267567 0.85627732 0.02720166]\n",
            " [0.18726755 0.77656051 0.02727799]\n",
            " [0.22968996 0.75839799 0.02246402]\n",
            " [0.87504269 0.12804038 0.00712153]\n",
            " [0.00205926 0.07258    0.97397985]\n",
            " [0.18955789 0.81116384 0.02224697]\n",
            " [0.00200867 0.06954716 0.975376  ]\n",
            " [0.00203066 0.07016632 0.97512972]\n",
            " [0.15966024 0.81644351 0.02633458]\n",
            " [0.79509855 0.21060837 0.00859729]\n",
            " [0.00200486 0.06946036 0.97531261]\n",
            " [0.87773659 0.12528403 0.00709668]\n",
            " [0.87996261 0.12267987 0.00703362]\n",
            " [0.7908919  0.20770205 0.00929917]\n",
            " [0.08647292 0.88902444 0.03706711]\n",
            " [0.12404241 0.85575453 0.02956291]\n",
            " [0.8354016  0.16905705 0.00786789]\n",
            " [0.79045741 0.21399637 0.00882797]\n",
            " [0.49489189 0.51643041 0.01368585]\n",
            " [0.00205844 0.06908543 0.97560094]\n",
            " [0.86383367 0.13870704 0.00739476]\n",
            " [0.00203066 0.07016632 0.97512972]\n",
            " [0.00207918 0.07458046 0.97303886]\n",
            " [0.00204471 0.07225373 0.97417317]\n",
            " [0.58389014 0.39943022 0.01392895]\n",
            " [0.28845759 0.69743673 0.02006096]\n",
            " [0.04897133 0.86818463 0.0686454 ]\n",
            " [0.00205823 0.07109726 0.9746014 ]\n",
            " [0.82569928 0.1787183  0.0081969 ]\n",
            " [0.16054855 0.82848619 0.02629468]\n",
            " [0.29569072 0.70144512 0.01863404]\n",
            " [0.88351242 0.11928166 0.00694812]\n",
            " [0.00213807 0.08107438 0.96967392]\n",
            " [0.86428512 0.13905081 0.00735942]\n",
            " [0.74287591 0.26302675 0.00966956]\n",
            " [0.87999289 0.12250319 0.00708131]\n",
            " [0.00202161 0.06993134 0.97514197]\n",
            " [0.11821672 0.80863014 0.0398704 ]\n",
            " [0.77382895 0.23011405 0.00952202]\n",
            " [0.06732865 0.89247836 0.04585831]\n",
            " [0.81857797 0.18311445 0.00834548]\n",
            " [0.41502915 0.58174194 0.0161511 ]\n",
            " [0.09877853 0.8692661  0.03597965]\n",
            " [0.47267541 0.53588612 0.01419991]\n",
            " [0.15899972 0.81397749 0.02702505]\n",
            " [0.06178324 0.86157714 0.06315216]\n",
            " [0.00202823 0.07026131 0.97501305]\n",
            " [0.84528635 0.15859947 0.00773348]\n",
            " [0.62051414 0.38608602 0.01162965]\n",
            " [0.00206854 0.0709614  0.97469014]\n",
            " [0.00201141 0.06849309 0.97578191]\n",
            " [0.0020159  0.07169391 0.97440044]\n",
            " [0.00205008 0.07170416 0.97429853]\n",
            " [0.19615235 0.78901874 0.02457461]\n",
            " [0.65212487 0.35609726 0.01115074]\n",
            " [0.08580015 0.88741984 0.03750815]\n",
            " [0.56668662 0.40932502 0.01401074]\n",
            " [0.00205104 0.0750884  0.97256956]\n",
            " [0.30151638 0.69469817 0.01893216]\n",
            " [0.00203262 0.06987489 0.97518428]\n",
            " [0.79865745 0.20494512 0.00880621]\n",
            " [0.30741642 0.69622263 0.01808998]\n",
            " [0.00207532 0.07436746 0.97293337]\n",
            " [0.00207305 0.07200579 0.97422381]\n",
            " [0.00203471 0.07052162 0.97490075]\n",
            " [0.00203541 0.06990317 0.97521629]\n",
            " [0.79970948 0.20541163 0.00861514]\n",
            " [0.87177894 0.13157411 0.00715667]\n",
            " [0.88015941 0.1226818  0.00702057]\n",
            " [0.14039458 0.83765277 0.02849603]\n",
            " [0.8613759  0.14220624 0.00737211]\n",
            " [0.0020386  0.07280298 0.97369773]\n",
            " [0.00201037 0.07392498 0.97308749]\n",
            " [0.77088506 0.23227046 0.00936032]\n",
            " [0.8598815  0.1434246  0.00745726]\n",
            " [0.82569928 0.1787183  0.0081969 ]\n",
            " [0.0020975  0.07584905 0.97226895]\n",
            " [0.30058192 0.69116204 0.01892897]\n",
            " [0.11939033 0.78621623 0.04395688]\n",
            " [0.00219524 0.11369764 0.95395562]\n",
            " [0.86849187 0.13468191 0.00726386]\n",
            " [0.76934371 0.23443032 0.00932721]\n",
            " [0.06556132 0.88559928 0.04795209]\n",
            " [0.87612613 0.12604859 0.00722179]\n",
            " [0.10620473 0.87417561 0.03240555]\n",
            " [0.00204001 0.07385043 0.97345628]\n",
            " [0.07122075 0.90813002 0.03784672]\n",
            " [0.79225395 0.21362359 0.00873381]]\n",
            "prediction:\n",
            " [[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOdVhZr4plOI",
        "outputId": "69548d76-31e5-4ecb-f8c7-4087dcafc8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(X,y):\n",
        "    X=X_test.to_numpy()\n",
        "    y=Y_test.to_numpy()\n",
        "    z_h=np.matmul(X,w1)\n",
        "    a_h=sigmoid(z_h)\n",
        "    z_h2=np.matmul(a_h,w2)\n",
        "    a_h2=sigmoid(z_h2)\n",
        "    z_o=np.matmul(a_h2,w3)\n",
        "    a_o=sigmoid(z_o) \n",
        "    pred_test=predict_(X,w1,w2,w3)\n",
        "    error = (0.5*(np.power((a_o-y),2)))\n",
        "    acc=(np.sum(y==np.round(pred_test),axis=1)==3).sum()\n",
        "    print(f'\\t Accuracy : {acc*100/len(X)} %')\n",
        "    print(f'error in Test set:  {np.sum(error)}')    \n",
        "test(X_test,Y_test)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFLkcsuBTkpT",
        "outputId": "7bcbd1b5-7410-456b-85ac-59bcbebefe69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Accuracy : 96.66666666666667 %\n",
            "error in Test set:  1.1587936840130888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title(\"training & validation loss vs epoch.\")\n",
        "plt.plot(np.arange(len(train_error)-1),train_error[:-1],\"r\")\n",
        "plt.plot(np.arange(len(validation_error)-1),validation_error[:-1],\"b\")\n",
        "plt.plot(np.arange(len(train_acc)-1),train_acc[:-1],\"y\")\n",
        "plt.plot(np.arange(len(validation_acc)-1),validation_acc[:-1],\"g\")\n",
        "plt.legend([\"training loss\",\"validation loss\",\"training_acc\",\"validation_acc\"])\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Errors\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "eht4PwxF53Fc",
        "outputId": "e277479d-e72d-43e7-e220-c3396b0abcc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution: Task - 2"
      ],
      "metadata": {
        "id": "8Hk4oDAQEGgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codes for Task 2\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "mode = keras.models.Sequential([\n",
        "keras.layers.InputLayer(input_shape=4,dtype='float32'),\n",
        "keras.layers.Dense(6, activation=\"relu\"),\n",
        "keras.layers.Dense(4, activation=\"relu\"),\n",
        "keras.layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "mode.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZnx3_6bTG-N",
        "outputId": "000553da-2ea8-494c-b17c-a667aac5cd36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 28        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73\n",
            "Trainable params: 73\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
        "restore_best_weights=True)\n",
        "mode.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "history=mode.fit(X_train, Y_train, epochs=50, batch_size=8,validation_data=(X_valid,Y_valid),callbacks=[early_stopping_cb])\n",
        "_, accuracy = mode.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "id": "pVHnDoDVBRod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "387d8a52-9d3f-4fea-f023-8469b9932214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 0.6953 - accuracy: 0.3125 - val_loss: 0.6919 - val_accuracy: 0.2500\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.3542 - val_loss: 0.6866 - val_accuracy: 0.2917\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.3750 - val_loss: 0.6814 - val_accuracy: 0.3750\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6777 - accuracy: 0.4062 - val_loss: 0.6753 - val_accuracy: 0.4167\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.4271 - val_loss: 0.6689 - val_accuracy: 0.5417\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.4583 - val_loss: 0.6619 - val_accuracy: 0.5417\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.4896 - val_loss: 0.6539 - val_accuracy: 0.5417\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.5521 - val_loss: 0.6452 - val_accuracy: 0.5417\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.5625 - val_loss: 0.6358 - val_accuracy: 0.7083\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6458 - val_loss: 0.6255 - val_accuracy: 0.7500\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.7083 - val_loss: 0.6147 - val_accuracy: 0.8333\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6103 - accuracy: 0.7708 - val_loss: 0.6035 - val_accuracy: 0.8333\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.7708 - val_loss: 0.5919 - val_accuracy: 0.8333\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7604 - val_loss: 0.5793 - val_accuracy: 0.8333\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.7604 - val_loss: 0.5659 - val_accuracy: 0.8750\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5590 - accuracy: 0.7604 - val_loss: 0.5519 - val_accuracy: 0.8750\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7812 - val_loss: 0.5377 - val_accuracy: 0.8750\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.8750\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.8750\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7917 - val_loss: 0.4932 - val_accuracy: 0.8750\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.8021 - val_loss: 0.4787 - val_accuracy: 0.8750\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.8125 - val_loss: 0.4644 - val_accuracy: 0.8750\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.8125 - val_loss: 0.4499 - val_accuracy: 0.8750\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.8125 - val_loss: 0.4359 - val_accuracy: 0.8750\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8125 - val_loss: 0.4227 - val_accuracy: 0.8333\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8229 - val_loss: 0.4103 - val_accuracy: 0.8333\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8229 - val_loss: 0.3984 - val_accuracy: 0.8333\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8021 - val_loss: 0.3876 - val_accuracy: 0.8750\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8021 - val_loss: 0.3776 - val_accuracy: 0.8750\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8021 - val_loss: 0.3687 - val_accuracy: 0.8750\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8021 - val_loss: 0.3602 - val_accuracy: 0.8750\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3603 - accuracy: 0.8021 - val_loss: 0.3525 - val_accuracy: 0.8750\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8125 - val_loss: 0.3450 - val_accuracy: 0.8750\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8125 - val_loss: 0.3380 - val_accuracy: 0.8750\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8125 - val_loss: 0.3313 - val_accuracy: 0.9167\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8125 - val_loss: 0.3248 - val_accuracy: 0.9167\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8125 - val_loss: 0.3184 - val_accuracy: 0.9167\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8125 - val_loss: 0.3122 - val_accuracy: 0.9167\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3191 - accuracy: 0.8125 - val_loss: 0.3065 - val_accuracy: 0.9167\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8125 - val_loss: 0.3009 - val_accuracy: 0.9167\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8125 - val_loss: 0.2955 - val_accuracy: 0.9167\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8125 - val_loss: 0.2901 - val_accuracy: 0.8750\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8125 - val_loss: 0.2850 - val_accuracy: 0.8750\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8229 - val_loss: 0.2801 - val_accuracy: 0.8750\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2926 - accuracy: 0.8229 - val_loss: 0.2752 - val_accuracy: 0.8750\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.8229 - val_loss: 0.2704 - val_accuracy: 0.8750\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2849 - accuracy: 0.8229 - val_loss: 0.2658 - val_accuracy: 0.8750\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.8229 - val_loss: 0.2616 - val_accuracy: 0.8750\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.8229 - val_loss: 0.2574 - val_accuracy: 0.8750\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.8229 - val_loss: 0.2533 - val_accuracy: 0.8750\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2721 - accuracy: 0.8229\n",
            "Accuracy: 82.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIeSQqqoLa95",
        "outputId": "479c15af-a0b3-4283-c182-662c59839102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 122ms/step - loss: 0.2226 - accuracy: 0.9000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2225990891456604, 0.8999999761581421]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "Not58fkTLRlf",
        "outputId": "4cbd52fc-29e0-4aad-e5f3-9a2d7a37e98c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz9Is7DBQIIN",
        "outputId": "0f27c1c9-d7cc-48d7-aca3-f223d72bc6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution: Task - 3"
      ],
      "metadata": {
        "id": "BqiUZc6tEISw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.layers.core import Dense\n",
        "# Codes for Task 3\n",
        "model2 = keras.models.Sequential([\n",
        "keras.layers.InputLayer(input_shape=4,dtype='float32'),\n",
        "keras.layers.Dense(6, activation=\"relu\"),\n",
        "keras.layers.Dense(4, activation=\"relu\"),\n",
        "keras.layers.Dense(6,activation=\"relu\"),\n",
        "keras.layers.Dense(8,activation=\"relu\"),\n",
        "keras.layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "model2.summary()\n",
        "model3 = keras.models.Sequential([\n",
        "keras.layers.InputLayer(input_shape=4,dtype='float32'),\n",
        "keras.layers.Dense(6, activation=\"relu\"),\n",
        "keras.layers.Dense(4, activation=\"relu\"),\n",
        "keras.layers.Dense(6,activation=\"relu\"),\n",
        "keras.layers.Dense(8,activation=\"relu\"),\n",
        "keras.layers.Dense(3,activation=\"relu\"),\n",
        "keras.layers.Dense(6,activation=\"relu\"),\n",
        "keras.layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "WLFoe8xNBS4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c668087e-8c84-4b84-a6a6-e3aa1deb02b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 28        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 56        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 171\n",
            "Trainable params: 171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4)                 28        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 8)                 56        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 6)                 24        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 3)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 216\n",
            "Trainable params: 216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model2.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "history2=model2.fit(X_train, Y_train, epochs=50, batch_size=8,validation_data=(X_valid,Y_valid),callbacks=[early_stopping_cb])\n",
        "_, accuracy = model2.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PiRTHm6ZzH_",
        "outputId": "1c23c6ae-8332-40ea-bf51-1a90bff0f0c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 0.6782 - accuracy: 0.6042 - val_loss: 0.6656 - val_accuracy: 0.6250\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.6458 - val_loss: 0.6561 - val_accuracy: 0.6250\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6613 - accuracy: 0.6458 - val_loss: 0.6462 - val_accuracy: 0.6250\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.6458 - val_loss: 0.6354 - val_accuracy: 0.6250\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6458 - val_loss: 0.6233 - val_accuracy: 0.6250\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.6458 - val_loss: 0.6114 - val_accuracy: 0.6250\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6175 - accuracy: 0.6458 - val_loss: 0.5985 - val_accuracy: 0.6250\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6037 - accuracy: 0.6458 - val_loss: 0.5843 - val_accuracy: 0.6250\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5888 - accuracy: 0.6458 - val_loss: 0.5692 - val_accuracy: 0.6250\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5725 - accuracy: 0.6562 - val_loss: 0.5542 - val_accuracy: 0.6250\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5544 - accuracy: 0.6562 - val_loss: 0.5383 - val_accuracy: 0.6250\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.6562 - val_loss: 0.5215 - val_accuracy: 0.6250\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.6667 - val_loss: 0.5040 - val_accuracy: 0.6250\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.6667 - val_loss: 0.4865 - val_accuracy: 0.6250\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.6667 - val_loss: 0.4682 - val_accuracy: 0.6250\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.6667 - val_loss: 0.4503 - val_accuracy: 0.6250\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.6667 - val_loss: 0.4338 - val_accuracy: 0.6250\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.6667 - val_loss: 0.4185 - val_accuracy: 0.6250\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.6667 - val_loss: 0.4041 - val_accuracy: 0.6250\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.6667 - val_loss: 0.3911 - val_accuracy: 0.6250\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.6667 - val_loss: 0.3799 - val_accuracy: 0.6250\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.6667 - val_loss: 0.3698 - val_accuracy: 0.6250\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.6667 - val_loss: 0.3604 - val_accuracy: 0.6250\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.6771 - val_loss: 0.3523 - val_accuracy: 0.6250\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.6771 - val_loss: 0.3455 - val_accuracy: 0.6250\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.6771 - val_loss: 0.3393 - val_accuracy: 0.6250\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3357 - accuracy: 0.6771 - val_loss: 0.3323 - val_accuracy: 0.6250\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.6875 - val_loss: 0.3265 - val_accuracy: 0.6250\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.6875 - val_loss: 0.3208 - val_accuracy: 0.6250\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.6875 - val_loss: 0.3156 - val_accuracy: 0.6250\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.6875 - val_loss: 0.3095 - val_accuracy: 0.6250\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.6875 - val_loss: 0.3031 - val_accuracy: 0.6250\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.6875 - val_loss: 0.2971 - val_accuracy: 0.6250\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8125 - val_loss: 0.2906 - val_accuracy: 0.9167\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.8438 - val_loss: 0.2837 - val_accuracy: 0.8750\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2911 - accuracy: 0.8542 - val_loss: 0.2777 - val_accuracy: 0.9167\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.8750 - val_loss: 0.2710 - val_accuracy: 0.9167\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2787 - accuracy: 0.8750 - val_loss: 0.2633 - val_accuracy: 0.9167\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2725 - accuracy: 0.9375 - val_loss: 0.2542 - val_accuracy: 0.9583\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2643 - accuracy: 0.9479 - val_loss: 0.2471 - val_accuracy: 0.9583\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2565 - accuracy: 0.9479 - val_loss: 0.2394 - val_accuracy: 0.9583\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9688 - val_loss: 0.2311 - val_accuracy: 0.9583\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2418 - accuracy: 0.9583 - val_loss: 0.2245 - val_accuracy: 0.9583\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9583 - val_loss: 0.2158 - val_accuracy: 0.9583\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2257 - accuracy: 0.9583 - val_loss: 0.2078 - val_accuracy: 0.9583\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2192 - accuracy: 0.9583 - val_loss: 0.1985 - val_accuracy: 0.9583\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2107 - accuracy: 0.9583 - val_loss: 0.1932 - val_accuracy: 0.9583\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2033 - accuracy: 0.9583 - val_loss: 0.1859 - val_accuracy: 0.9583\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9583 - val_loss: 0.1813 - val_accuracy: 0.9583\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1895 - accuracy: 0.9583 - val_loss: 0.1689 - val_accuracy: 0.9583\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1854 - accuracy: 0.9583\n",
            "Accuracy: 95.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with 4 hidden layers"
      ],
      "metadata": {
        "id": "089rulZCKUFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q47rjSt3C-eW",
        "outputId": "71b4677c-b00a-422e-dfc0-daf50985d7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 145ms/step - loss: 0.1499 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14993639290332794, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "history3=model3.fit(X_train, Y_train, epochs=50, batch_size=8,validation_data=(X_valid,Y_valid),callbacks=[early_stopping_cb])\n",
        "_, accuracy = model2.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqCHyuiqZ6OO",
        "outputId": "f28c87a0-3c49-41cf-e429-099ce712525e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 0.6899 - accuracy: 0.3021 - val_loss: 0.6889 - val_accuracy: 0.2500\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.3750 - val_loss: 0.6843 - val_accuracy: 0.2917\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6795 - accuracy: 0.3125 - val_loss: 0.6793 - val_accuracy: 0.2917\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.3125 - val_loss: 0.6739 - val_accuracy: 0.2917\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.3125 - val_loss: 0.6674 - val_accuracy: 0.2917\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.3125 - val_loss: 0.6587 - val_accuracy: 0.2917\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.3125 - val_loss: 0.6469 - val_accuracy: 0.2917\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.3125 - val_loss: 0.6327 - val_accuracy: 0.2917\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6140 - accuracy: 0.3125 - val_loss: 0.6123 - val_accuracy: 0.2917\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.3125 - val_loss: 0.5891 - val_accuracy: 0.2917\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5659 - accuracy: 0.3125 - val_loss: 0.5660 - val_accuracy: 0.2917\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.3125 - val_loss: 0.5428 - val_accuracy: 0.2917\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.3125 - val_loss: 0.5210 - val_accuracy: 0.2917\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.3125 - val_loss: 0.5021 - val_accuracy: 0.2917\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.4479 - val_loss: 0.4881 - val_accuracy: 0.6667\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.5729 - val_loss: 0.4753 - val_accuracy: 0.6667\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.6146 - val_loss: 0.4650 - val_accuracy: 0.6667\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.6146 - val_loss: 0.4563 - val_accuracy: 0.6667\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.6667 - val_loss: 0.4484 - val_accuracy: 0.7083\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.6875 - val_loss: 0.4408 - val_accuracy: 0.7500\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.6875 - val_loss: 0.4336 - val_accuracy: 0.6667\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7604 - val_loss: 0.4263 - val_accuracy: 0.6667\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.7604 - val_loss: 0.4187 - val_accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.7604 - val_loss: 0.4116 - val_accuracy: 0.7500\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.7604 - val_loss: 0.4048 - val_accuracy: 0.8333\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.7812 - val_loss: 0.3979 - val_accuracy: 0.8333\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.7708 - val_loss: 0.3908 - val_accuracy: 0.8333\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.7708 - val_loss: 0.3844 - val_accuracy: 0.8333\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.7604 - val_loss: 0.3782 - val_accuracy: 0.6250\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.7604 - val_loss: 0.3720 - val_accuracy: 0.7917\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.7812 - val_loss: 0.3666 - val_accuracy: 0.6250\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3547 - accuracy: 0.7604 - val_loss: 0.3613 - val_accuracy: 0.8333\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.7604 - val_loss: 0.3565 - val_accuracy: 0.9167\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.7708 - val_loss: 0.3522 - val_accuracy: 0.8750\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3413 - accuracy: 0.7812 - val_loss: 0.3482 - val_accuracy: 0.8333\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.7812 - val_loss: 0.3450 - val_accuracy: 0.8750\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.7812 - val_loss: 0.3416 - val_accuracy: 0.8333\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3312 - accuracy: 0.8021 - val_loss: 0.3384 - val_accuracy: 0.7917\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.7604 - val_loss: 0.3350 - val_accuracy: 0.7083\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.7396 - val_loss: 0.3323 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.7500 - val_loss: 0.3297 - val_accuracy: 0.7083\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.7083 - val_loss: 0.3268 - val_accuracy: 0.6667\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.6979 - val_loss: 0.3244 - val_accuracy: 0.6667\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.6875 - val_loss: 0.3212 - val_accuracy: 0.6667\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3149 - accuracy: 0.6771 - val_loss: 0.3187 - val_accuracy: 0.6667\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.6458 - val_loss: 0.3147 - val_accuracy: 0.6667\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.6458 - val_loss: 0.3122 - val_accuracy: 0.6667\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3096 - accuracy: 0.6458 - val_loss: 0.3084 - val_accuracy: 0.6667\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3079 - accuracy: 0.6562 - val_loss: 0.3078 - val_accuracy: 0.6667\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.6562 - val_loss: 0.3043 - val_accuracy: 0.6667\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9583\n",
            "Accuracy: 95.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with 6 hidden layers"
      ],
      "metadata": {
        "id": "hzTJwZtxKbJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkeV9vb8DFjk",
        "outputId": "3501171c-1c8d-4709-db82-e3ed57f98a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 140ms/step - loss: 0.2438 - accuracy: 0.7667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24377962946891785, 0.7666666507720947]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sigmoid = keras.models.Sequential([\n",
        "keras.layers.InputLayer(input_shape=4,dtype='float32'),\n",
        "keras.layers.Dense(6, activation=\"sigmoid\"),\n",
        "keras.layers.Dense(4, activation=\"sigmoid\"),\n",
        "keras.layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "model_sigmoid.summary()\n",
        "model_tanh=keras.models.Sequential([\n",
        "keras.layers.InputLayer(input_shape=4,dtype='float32'),\n",
        "keras.layers.Dense(6, activation=keras.activations.tanh),\n",
        "keras.layers.Dense(4, activation=keras.activations.tanh),\n",
        "keras.layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "model_tanh.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1KhaBk1d2WN",
        "outputId": "45fe0044-bea3-4f95-81ea-923665c46b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 4)                 28        \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 3)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73\n",
            "Trainable params: 73\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 4)                 28        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 3)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73\n",
            "Trainable params: 73\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sigmoid.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "history3=model_sigmoid.fit(X_train, Y_train, epochs=50, batch_size=8,validation_data=(X_valid,Y_valid),callbacks=[early_stopping_cb])\n",
        "_, accuracy = model2.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wRsjVOVySPK",
        "outputId": "a6a21f70-0c24-4fcf-cb41-f74e62551f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 0.9588 - accuracy: 0.3333 - val_loss: 0.9412 - val_accuracy: 0.3750\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9376 - accuracy: 0.3333 - val_loss: 0.9209 - val_accuracy: 0.3750\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9179 - accuracy: 0.3333 - val_loss: 0.9019 - val_accuracy: 0.3750\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8995 - accuracy: 0.3333 - val_loss: 0.8843 - val_accuracy: 0.3750\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8823 - accuracy: 0.3333 - val_loss: 0.8679 - val_accuracy: 0.3750\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8664 - accuracy: 0.3333 - val_loss: 0.8526 - val_accuracy: 0.3750\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8516 - accuracy: 0.3333 - val_loss: 0.8385 - val_accuracy: 0.3750\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8379 - accuracy: 0.3333 - val_loss: 0.8254 - val_accuracy: 0.3750\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8251 - accuracy: 0.3333 - val_loss: 0.8132 - val_accuracy: 0.3750\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8132 - accuracy: 0.3333 - val_loss: 0.8019 - val_accuracy: 0.3750\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8023 - accuracy: 0.3333 - val_loss: 0.7914 - val_accuracy: 0.3750\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7920 - accuracy: 0.3333 - val_loss: 0.7816 - val_accuracy: 0.3750\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7824 - accuracy: 0.3333 - val_loss: 0.7724 - val_accuracy: 0.3750\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7735 - accuracy: 0.3333 - val_loss: 0.7638 - val_accuracy: 0.3750\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7650 - accuracy: 0.3333 - val_loss: 0.7558 - val_accuracy: 0.3750\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7571 - accuracy: 0.3333 - val_loss: 0.7482 - val_accuracy: 0.3750\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7497 - accuracy: 0.3333 - val_loss: 0.7411 - val_accuracy: 0.3750\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.3333 - val_loss: 0.7344 - val_accuracy: 0.3750\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7362 - accuracy: 0.3333 - val_loss: 0.7281 - val_accuracy: 0.3750\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7300 - accuracy: 0.3333 - val_loss: 0.7221 - val_accuracy: 0.3750\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7241 - accuracy: 0.3333 - val_loss: 0.7164 - val_accuracy: 0.3750\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7186 - accuracy: 0.3333 - val_loss: 0.7110 - val_accuracy: 0.3750\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7133 - accuracy: 0.3333 - val_loss: 0.7059 - val_accuracy: 0.3750\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.3333 - val_loss: 0.7010 - val_accuracy: 0.3750\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7035 - accuracy: 0.3333 - val_loss: 0.6964 - val_accuracy: 0.3750\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.3333 - val_loss: 0.6919 - val_accuracy: 0.3750\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.3333 - val_loss: 0.6876 - val_accuracy: 0.3750\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.3333 - val_loss: 0.6835 - val_accuracy: 0.3750\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.3333 - val_loss: 0.6796 - val_accuracy: 0.3750\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.3333 - val_loss: 0.6758 - val_accuracy: 0.3750\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.3333 - val_loss: 0.6722 - val_accuracy: 0.3750\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.3333 - val_loss: 0.6686 - val_accuracy: 0.3750\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.3333 - val_loss: 0.6652 - val_accuracy: 0.3750\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.3333 - val_loss: 0.6619 - val_accuracy: 0.3750\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.3333 - val_loss: 0.6588 - val_accuracy: 0.3750\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.3333 - val_loss: 0.6556 - val_accuracy: 0.3750\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6590 - accuracy: 0.3333 - val_loss: 0.6526 - val_accuracy: 0.3750\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.3333 - val_loss: 0.6497 - val_accuracy: 0.3750\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.3333 - val_loss: 0.6468 - val_accuracy: 0.3750\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.3333 - val_loss: 0.6441 - val_accuracy: 0.3750\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6477 - accuracy: 0.3333 - val_loss: 0.6414 - val_accuracy: 0.3750\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.3333 - val_loss: 0.6388 - val_accuracy: 0.3750\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6425 - accuracy: 0.3333 - val_loss: 0.6363 - val_accuracy: 0.3750\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6400 - accuracy: 0.3333 - val_loss: 0.6338 - val_accuracy: 0.3750\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.3333 - val_loss: 0.6314 - val_accuracy: 0.3750\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.3333 - val_loss: 0.6290 - val_accuracy: 0.3750\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6329 - accuracy: 0.3333 - val_loss: 0.6267 - val_accuracy: 0.3750\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.3333 - val_loss: 0.6244 - val_accuracy: 0.3750\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.3333 - val_loss: 0.6222 - val_accuracy: 0.3750\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.3333 - val_loss: 0.6201 - val_accuracy: 0.3750\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1854 - accuracy: 0.9583\n",
            "Accuracy: 95.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with sigmoid activation function"
      ],
      "metadata": {
        "id": "O4majk75KhsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_sigmoid.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4fULivMDQRJ",
        "outputId": "129c9493-0b66-48ee-d93d-f3957375dfb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 112ms/step - loss: 0.6329 - accuracy: 0.3000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.632863461971283, 0.30000001192092896]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_tanh.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "history3=model_tanh.fit(X_train, Y_train, epochs=50, batch_size=8,validation_data=(X_valid,Y_valid),callbacks=[early_stopping_cb])\n",
        "_, accuracy = model2.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07BmFuk-yWwE",
        "outputId": "e7a12728-bf7b-482d-d293-21888478000a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 0.7197 - accuracy: 0.2708 - val_loss: 0.6833 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7017 - accuracy: 0.3646 - val_loss: 0.6670 - val_accuracy: 0.4167\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.4479 - val_loss: 0.6512 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5521 - val_loss: 0.6365 - val_accuracy: 0.5833\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.6146 - val_loss: 0.6230 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6771 - val_loss: 0.6107 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6285 - accuracy: 0.7083 - val_loss: 0.5990 - val_accuracy: 0.7917\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.7292 - val_loss: 0.5876 - val_accuracy: 0.7917\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.7396 - val_loss: 0.5773 - val_accuracy: 0.7917\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7500 - val_loss: 0.5674 - val_accuracy: 0.7917\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.7604 - val_loss: 0.5574 - val_accuracy: 0.7917\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.7917\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7604 - val_loss: 0.5383 - val_accuracy: 0.7917\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.7604 - val_loss: 0.5288 - val_accuracy: 0.7917\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7604 - val_loss: 0.5196 - val_accuracy: 0.7917\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7604 - val_loss: 0.5103 - val_accuracy: 0.7917\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7500 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7604 - val_loss: 0.4919 - val_accuracy: 0.7917\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7708 - val_loss: 0.4831 - val_accuracy: 0.7917\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7708 - val_loss: 0.4750 - val_accuracy: 0.8333\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7708 - val_loss: 0.4669 - val_accuracy: 0.8333\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7604 - val_loss: 0.4597 - val_accuracy: 0.8333\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7708 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7812 - val_loss: 0.4457 - val_accuracy: 0.8750\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7917 - val_loss: 0.4393 - val_accuracy: 0.8750\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7917 - val_loss: 0.4331 - val_accuracy: 0.8750\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.8021 - val_loss: 0.4276 - val_accuracy: 0.8750\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.8021 - val_loss: 0.4223 - val_accuracy: 0.8750\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8125 - val_loss: 0.4168 - val_accuracy: 0.8750\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.8125 - val_loss: 0.4119 - val_accuracy: 0.8750\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8125 - val_loss: 0.4072 - val_accuracy: 0.8750\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8125 - val_loss: 0.4024 - val_accuracy: 0.8750\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8125 - val_loss: 0.3980 - val_accuracy: 0.8750\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8125 - val_loss: 0.3939 - val_accuracy: 0.8750\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8229 - val_loss: 0.3899 - val_accuracy: 0.8750\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8229 - val_loss: 0.3858 - val_accuracy: 0.8750\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8125 - val_loss: 0.3821 - val_accuracy: 0.8750\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8125 - val_loss: 0.3788 - val_accuracy: 0.8750\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8229 - val_loss: 0.3748 - val_accuracy: 0.8750\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8333 - val_loss: 0.3712 - val_accuracy: 0.8750\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8438 - val_loss: 0.3676 - val_accuracy: 0.9167\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8438 - val_loss: 0.3641 - val_accuracy: 0.9167\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.8438 - val_loss: 0.3602 - val_accuracy: 0.9167\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8542 - val_loss: 0.3574 - val_accuracy: 0.9167\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8646 - val_loss: 0.3539 - val_accuracy: 0.9167\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8750 - val_loss: 0.3504 - val_accuracy: 0.9167\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3574 - accuracy: 0.8750 - val_loss: 0.3474 - val_accuracy: 0.9167\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8750 - val_loss: 0.3442 - val_accuracy: 0.9167\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8854 - val_loss: 0.3415 - val_accuracy: 0.9167\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3469 - accuracy: 0.8854 - val_loss: 0.3381 - val_accuracy: 0.9167\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1854 - accuracy: 0.9583\n",
            "Accuracy: 95.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with tanh activation function"
      ],
      "metadata": {
        "id": "3zn-E9BVKsLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_tanh.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL6rcqFcDVS8",
        "outputId": "f071a31e-7c7a-4e31-dd9b-21d58840da4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 110ms/step - loss: 0.3111 - accuracy: 0.9667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.311061292886734, 0.9666666388511658]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mode.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adagrad(), metrics=['accuracy'])\n",
        "history3=mode.fit(X_train, Y_train, epochs=50, batch_size=8,validation_data=(X_valid,Y_valid),callbacks=[early_stopping_cb])\n",
        "_, accuracy = mode.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy3AoDl0lJj8",
        "outputId": "168a82d0-1efd-401d-8463-9d705fcbc5f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 0.2720 - accuracy: 0.8229 - val_loss: 0.2529 - val_accuracy: 0.8750\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2717 - accuracy: 0.8229 - val_loss: 0.2525 - val_accuracy: 0.8750\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2714 - accuracy: 0.8229 - val_loss: 0.2521 - val_accuracy: 0.8750\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2711 - accuracy: 0.8229 - val_loss: 0.2518 - val_accuracy: 0.8750\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8229 - val_loss: 0.2515 - val_accuracy: 0.8750\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2706 - accuracy: 0.8229 - val_loss: 0.2512 - val_accuracy: 0.8750\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.8229 - val_loss: 0.2509 - val_accuracy: 0.8750\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2701 - accuracy: 0.8229 - val_loss: 0.2507 - val_accuracy: 0.8750\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2699 - accuracy: 0.8229 - val_loss: 0.2504 - val_accuracy: 0.8750\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.8229 - val_loss: 0.2502 - val_accuracy: 0.8750\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.8229 - val_loss: 0.2499 - val_accuracy: 0.8750\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2692 - accuracy: 0.8229 - val_loss: 0.2497 - val_accuracy: 0.8750\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.8229 - val_loss: 0.2495 - val_accuracy: 0.8750\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.8229 - val_loss: 0.2493 - val_accuracy: 0.8750\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2687 - accuracy: 0.8229 - val_loss: 0.2490 - val_accuracy: 0.8750\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2685 - accuracy: 0.8229 - val_loss: 0.2488 - val_accuracy: 0.8750\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.8229 - val_loss: 0.2486 - val_accuracy: 0.8750\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.8229 - val_loss: 0.2484 - val_accuracy: 0.8750\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2679 - accuracy: 0.8333 - val_loss: 0.2482 - val_accuracy: 0.8750\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.8333 - val_loss: 0.2480 - val_accuracy: 0.8750\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.8333 - val_loss: 0.2479 - val_accuracy: 0.8750\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2674 - accuracy: 0.8333 - val_loss: 0.2477 - val_accuracy: 0.8750\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2673 - accuracy: 0.8333 - val_loss: 0.2475 - val_accuracy: 0.8750\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.8333 - val_loss: 0.2473 - val_accuracy: 0.8750\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2670 - accuracy: 0.8333 - val_loss: 0.2471 - val_accuracy: 0.8750\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.8333 - val_loss: 0.2470 - val_accuracy: 0.8750\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2667 - accuracy: 0.8333 - val_loss: 0.2468 - val_accuracy: 0.8750\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.8333 - val_loss: 0.2466 - val_accuracy: 0.8750\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.8333 - val_loss: 0.2465 - val_accuracy: 0.8750\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2662 - accuracy: 0.8333 - val_loss: 0.2463 - val_accuracy: 0.8750\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2661 - accuracy: 0.8333 - val_loss: 0.2461 - val_accuracy: 0.8750\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.8333 - val_loss: 0.2460 - val_accuracy: 0.8750\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.8333 - val_loss: 0.2458 - val_accuracy: 0.8750\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.8333 - val_loss: 0.2457 - val_accuracy: 0.8750\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.8333 - val_loss: 0.2455 - val_accuracy: 0.8750\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2654 - accuracy: 0.8333 - val_loss: 0.2454 - val_accuracy: 0.8750\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8333 - val_loss: 0.2452 - val_accuracy: 0.8750\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.8333 - val_loss: 0.2451 - val_accuracy: 0.8750\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8333 - val_loss: 0.2449 - val_accuracy: 0.8750\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.8333 - val_loss: 0.2448 - val_accuracy: 0.8750\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8333 - val_loss: 0.2447 - val_accuracy: 0.8750\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2646 - accuracy: 0.8333 - val_loss: 0.2445 - val_accuracy: 0.8750\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.8333 - val_loss: 0.2444 - val_accuracy: 0.8750\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.8333 - val_loss: 0.2442 - val_accuracy: 0.8750\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2643 - accuracy: 0.8333 - val_loss: 0.2441 - val_accuracy: 0.8750\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2642 - accuracy: 0.8333 - val_loss: 0.2440 - val_accuracy: 0.8750\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2640 - accuracy: 0.8333 - val_loss: 0.2439 - val_accuracy: 0.8750\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2639 - accuracy: 0.8333 - val_loss: 0.2437 - val_accuracy: 0.8750\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2638 - accuracy: 0.8333 - val_loss: 0.2436 - val_accuracy: 0.8750\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2637 - accuracy: 0.8333 - val_loss: 0.2435 - val_accuracy: 0.8750\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2636 - accuracy: 0.8333\n",
            "Accuracy: 83.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with Adagrad Optimizer and 2 hidden layers"
      ],
      "metadata": {
        "id": "E06iZ-RUKxhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSsAnis4DeqP",
        "outputId": "2750f26e-3d89-4eae-d3d3-01ad35e28e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 113ms/step - loss: 0.2148 - accuracy: 0.9000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21477381885051727, 0.8999999761581421]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "history3=mode.fit(X_train, Y_train, epochs=50, batch_size=8,validation_data=(X_valid,Y_valid),callbacks=[early_stopping_cb])\n",
        "_, accuracy = mode.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BTiGGSAyKuj",
        "outputId": "d1cfcace-4ff4-45a1-dc09-c6d82d2dacb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 28ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2435 - val_accuracy: 0.8750\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2435 - val_accuracy: 0.8750\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2435 - val_accuracy: 0.8750\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2435 - val_accuracy: 0.8750\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2636 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2434 - val_accuracy: 0.8750\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.8750\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8333 - val_loss: 0.2432 - val_accuracy: 0.8750\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.8333\n",
            "Accuracy: 83.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with Adadelta Optimizer and 2 hidden layers"
      ],
      "metadata": {
        "id": "93mRkYEkK3sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_NNoRi6DjHk",
        "outputId": "5563c989-a1f7-4f53-8dc5-0da73e2c5a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 129ms/step - loss: 0.2146 - accuracy: 0.9000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21458452939987183, 0.8999999761581421]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\n",
        "history=mode.fit(X_train, Y_train, epochs=50, batch_size=8,validation_data=(X_valid,Y_valid),callbacks=[early_stopping_cb])\n",
        "_, accuracy = mode.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR6yZzQWJPVB",
        "outputId": "a9f8a2fd-874f-445f-e80c-32fa0aa24583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 0.2573 - accuracy: 0.8229 - val_loss: 0.2195 - val_accuracy: 0.8750\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2280 - accuracy: 0.8438 - val_loss: 0.1943 - val_accuracy: 0.9167\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.8646 - val_loss: 0.1725 - val_accuracy: 0.9167\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1852 - accuracy: 0.8750 - val_loss: 0.1619 - val_accuracy: 0.9167\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9271 - val_loss: 0.1593 - val_accuracy: 0.9167\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9375 - val_loss: 0.1374 - val_accuracy: 0.9167\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1379 - accuracy: 0.9271 - val_loss: 0.1240 - val_accuracy: 0.9167\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9271 - val_loss: 0.1208 - val_accuracy: 0.9167\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9271 - val_loss: 0.1034 - val_accuracy: 0.9583\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9375 - val_loss: 0.1047 - val_accuracy: 0.9167\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0935 - accuracy: 0.9375 - val_loss: 0.0846 - val_accuracy: 0.9583\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9479 - val_loss: 0.0757 - val_accuracy: 0.9583\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9479 - val_loss: 0.0757 - val_accuracy: 0.9167\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9479 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9583 - val_loss: 0.0740 - val_accuracy: 0.9167\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9479 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9479 - val_loss: 0.0617 - val_accuracy: 0.9167\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9583 - val_loss: 0.0533 - val_accuracy: 0.9167\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9583 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9479 - val_loss: 0.0480 - val_accuracy: 0.9583\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.9583 - val_loss: 0.0466 - val_accuracy: 0.9583\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9479 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9583 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9583 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9583 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9688 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9688 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.9688 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9688 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9688 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9688 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9688 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9688 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0504 - accuracy: 0.9688 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9688 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9583\n",
            "Accuracy: 95.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with Adam Optimizer and learning rate of 0.01"
      ],
      "metadata": {
        "id": "beIRm0ORLF1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLqh3DFGJQ0s",
        "outputId": "e00f3650-c025-4d43-a4da-50a379287ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0206 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.020557371899485588, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=1), metrics=['accuracy'])\n",
        "history=mode.fit(X_train, Y_train, epochs=50, batch_size=8,validation_data=(X_valid,Y_valid),callbacks=[early_stopping_cb])\n",
        "_, accuracy = mode.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vbizEufcGvk",
        "outputId": "176fbd03-4b99-4077-a3dc-b11f9384a45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 2.0849 - accuracy: 0.5625 - val_loss: 0.9829 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8496 - accuracy: 0.2812 - val_loss: 0.7799 - val_accuracy: 0.2917\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.3542 - val_loss: 0.6933 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.3021 - val_loss: 0.6418 - val_accuracy: 0.2917\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6806 - accuracy: 0.3333 - val_loss: 0.6416 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7291 - accuracy: 0.3021 - val_loss: 0.6566 - val_accuracy: 0.3750\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.3542 - val_loss: 0.6887 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6521 - accuracy: 0.3646 - val_loss: 0.6477 - val_accuracy: 0.3750\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.3542\n",
            "Accuracy: 35.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with Adam Optimizer and learning rate of 1"
      ],
      "metadata": {
        "id": "kfn_IY3zLMtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mptyyV8WDl-6",
        "outputId": "5d8c89f7-6d17-4e87-ad89-bed737e9b08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 344ms/step - loss: 0.6482 - accuracy: 0.2667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6481872797012329, 0.2666666805744171]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.1), metrics=['accuracy'])\n",
        "history=mode.fit(X_train, Y_train, epochs=50, batch_size=8,validation_data=(X_valid,Y_valid),callbacks=[early_stopping_cb])\n",
        "_, accuracy = mode.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5suMQP4yNKc",
        "outputId": "8dc2625d-9e88-4dd5-d70c-73b828c27c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 0.6504 - accuracy: 0.3125 - val_loss: 0.6422 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.3438 - val_loss: 0.6343 - val_accuracy: 0.3750\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.2917 - val_loss: 0.6359 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.3542 - val_loss: 0.6355 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6427 - accuracy: 0.3542 - val_loss: 0.6381 - val_accuracy: 0.3333\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.3333\n",
            "Accuracy: 33.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with Adam Optimizer and learning rate of 0.1"
      ],
      "metadata": {
        "id": "ysTTjja5LTG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU9uNj7vzEJF",
        "outputId": "4a806dfe-3c7d-4601-ba65-f5f2ed69f3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 119ms/step - loss: 0.6437 - accuracy: 0.3000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6436540484428406, 0.30000001192092896]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sjUzkuK4G1cv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}